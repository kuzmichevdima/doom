{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[this demo requires doom installed either from gym-pool or from [ppaquette's repo](https://github.com/ppaquette/gym-doom)]\n",
    "\n",
    "## Basic Doom demo\n",
    "\n",
    "* This demo solves DoomBasic env with a simple q-learning with experience replay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cuda,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%env THEANO_FLAGS=device=cuda,floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: Tesla K80 (0000:00:1E.0)\n",
      "[2017-06-27 00:19:47,041] Making new env: ppaquette/DoomDefendLine-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ppaquette_gym_doom\n",
    "from gym.wrappers import SkipWrapper\n",
    "from ppaquette_gym_doom.wrappers.action_space import ToDiscrete\n",
    "from agentnet.experiments.openai_gym.wrappers import PreprocessImage\n",
    "GAME_NAME = 'ppaquette/DoomDefendLine-v0'\n",
    "\n",
    "make_env = lambda: PreprocessImage(SkipWrapper(4)(ToDiscrete(\"minimal\")(gym.make(GAME_NAME))),\n",
    "                                   width=80,height=80,grayscale=True)\n",
    "\n",
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "N_AGENTS = 1\n",
    "SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0ea02802b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP/wkGSD/H1I32nrOrXrpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0eb4d1c470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "obs,r,done,_=env.step(1)\n",
    "print(r, done)\n",
    "plt.imshow(obs[0],cmap='gray',interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using simple convolutional neural network.\n",
    "\n",
    "![scheme](https://s18.postimg.org/gbmsq6gmx/dqn_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cuda,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "#setup and import theano/lasagne. Prefer GPU\n",
    "%env THEANO_FLAGS=device=cuda,floatX=float32\n",
    "\n",
    "import theano, lasagne\n",
    "from lasagne.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#observation\n",
    "observation_layer = InputLayer((None,)+observation_shape,)\n",
    "\n",
    "#4-tick window over images\n",
    "from agentnet.memory import WindowAugmentation, LSTMCell\n",
    "\n",
    "prev_wnd = InputLayer((None,4)+observation_shape)\n",
    "new_wnd = WindowAugmentation(observation_layer,prev_wnd)\n",
    "        \n",
    "#reshape to (frame, h,w). If you don't use grayscale, 4 should become 12.\n",
    "wnd_reshape = reshape(new_wnd, (-1,4*observation_shape[0])+observation_shape[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.nonlinearities import elu,tanh,softmax\n",
    "#main neural network body.\n",
    "#note that we use batch normalization here which speeds up training but may\n",
    "#get unstable if you use small experience replay buffer\n",
    "conv0 = Conv2DLayer(wnd_reshape,32,filter_size=(8,8),stride=(4,4),name='conv0')\n",
    "\n",
    "conv1 = Conv2DLayer(batch_norm(conv0),64,filter_size=(4,4),stride=(2,2),name='conv1')\n",
    "\n",
    "dense = DenseLayer(batch_norm(conv1),512,name='dense',nonlinearity = lasagne.nonlinearities.tanh)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ready_conv0 = Conv2DLayer(wnd_reshape,32,filter_size=(8,8),stride=(4,4),name='ready_conv0')\n",
    "\n",
    "ready_conv1 = Conv2DLayer(batch_norm(ready_conv0),64,filter_size=(4,4),stride=(2,2),name='ready_conv1')\n",
    "\n",
    "ready_dense = DenseLayer(batch_norm(ready_conv1),512,name='ready_dense',nonlinearity = lasagne.nonlinearities.tanh)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#baseline for all qvalues\n",
    "qvalues_layer = DenseLayer(dense,n_actions,nonlinearity=None,name='qval')\n",
    "        \n",
    "#sample actions proportionally to policy_layer\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ready_qvalues_layer = DenseLayer(ready_dense,n_actions,nonlinearity=None,name='ready_qval')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lasagne.layers.dense.DenseLayer at 0x7f0ea029bc88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agentnet.utils.persistence import save,load\n",
    "load(ready_qvalues_layer, \"dist_weights/line_saved_qvalues_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.target_network import TargetNetwork\n",
    "targetnet = TargetNetwork(ready_qvalues_layer)\n",
    "qvalues_right = targetnet.output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=(qvalues_layer,qvalues_right),\n",
    "              agent_states={new_wnd:prev_wnd},\n",
    "              action_layers=action_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[conv0.W,\n",
       " conv0_bn.beta,\n",
       " conv0_bn.gamma,\n",
       " conv1.W,\n",
       " conv1_bn.beta,\n",
       " conv1_bn.gamma,\n",
       " dense.W,\n",
       " dense.b,\n",
       " qval.W,\n",
       " qval.b]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:19:48,071] Making new env: ppaquette/DoomDefendLine-v0\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "\n",
    "pool = EnvPool(agent,make_env, \n",
    "               n_games=N_AGENTS,\n",
    "               max_size=300) #experience replay pool holding last 1k sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0 3 0 1 1 0]]\n",
      "[[ 0.  0.  0.  0.  1.  0.  0.]]\n",
      "CPU times: user 32 ms, sys: 4 ms, total: 36 ms\n",
      "Wall time: 86.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_,action_log,reward_log,_,_,_  = pool.interact(7)\n",
    "\n",
    "\n",
    "print(action_log[:2])\n",
    "print(reward_log[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100,replace=True)\n",
    "\n",
    "_,_,_,_,(qvalues_seq,right_qvalues_seq) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "theano.tensor.var.TensorVariable"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(right_qvalues_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.learning import qlearning\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.objectives import squared_error\n",
    "import numpy as np\n",
    "def my_softmax(x):\n",
    "    e_x = theano.tensor.exp(x - x.max(axis=1, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tau = 0.01\n",
    "softmax_T = my_softmax(right_qvalues_seq / tau)\n",
    "softmax_S = my_softmax(qvalues_seq / tau)\n",
    "elwise_loss = softmax_T * np.log(softmax_T / softmax_S)\n",
    "#elwise_loss = squared_error(right_qvalues_seq, qvalues_seq)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.adam(loss,weights)\n",
    "\n",
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:20:18,289] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:20:18,298] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2017-06-27 00:20:18,543] Starting new video recorder writing to /home/ubuntu/records/openaigym.video.0.17267.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 57 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:20:19,965] Starting new video recorder writing to /home/ubuntu/records/openaigym.video.0.17267.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 73 timesteps with reward=3.0\n",
      "Episode finished after 84 timesteps with reward=3.0\n",
      "Episode finished after 51 timesteps with reward=1.0\n",
      "Episode finished after 109 timesteps with reward=6.0\n",
      "Episode finished after 48 timesteps with reward=2.0\n",
      "Episode finished after 79 timesteps with reward=5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:20:27,262] Starting new video recorder writing to /home/ubuntu/records/openaigym.video.0.17267.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 46 timesteps with reward=0.0\n",
      "Episode finished after 61 timesteps with reward=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:20:29,220] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 40 timesteps with reward=1.0\n"
     ]
    }
   ],
   "source": [
    "action_layer.epsilon.set_value(0)\n",
    "untrained_reward = np.mean(pool.evaluate(save_path=\"./records\",record_video=True,n_games=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./records/openaigym.video.0.17267.video000008.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./records/\"+video_names[-1])) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {0:[untrained_reward]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/2000 [00:02<07:33,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10\tepsilon=0.954\treward/step=0.05455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 21/2000 [00:04<07:30,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=20\tepsilon=0.910\treward/step=0.06667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 31/2000 [00:07<07:19,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=30\tepsilon=0.868\treward/step=0.06129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 40/2000 [00:09<08:14,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=40\tepsilon=0.828\treward/step=0.06829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 49/2000 [00:11<07:59,  4.07it/s][2017-06-27 00:20:41,094] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:20:41,102] Clearing 8 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=50\tepsilon=0.790\treward/step=0.06471\n",
      "Episode finished after 89 timesteps with reward=6.0\n",
      "Episode finished after 158 timesteps with reward=15.0\n",
      "Episode finished after 149 timesteps with reward=16.0\n",
      "Episode finished after 112 timesteps with reward=9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:20:49,914] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      "  2%|▎         | 50/2000 [00:20<1:34:40,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 120 timesteps with reward=7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 60/2000 [00:23<11:15,  2.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=60\tepsilon=0.754\treward/step=0.05902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 70/2000 [00:25<08:31,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=70\tepsilon=0.719\treward/step=0.06338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 80/2000 [00:28<08:13,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=80\tepsilon=0.687\treward/step=0.06173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 90/2000 [00:30<08:30,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=90\tepsilon=0.656\treward/step=0.06044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 99/2000 [00:33<08:06,  3.91it/s][2017-06-27 00:21:02,806] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:21:02,811] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=100\tepsilon=0.626\treward/step=0.06436\n",
      "Episode finished after 90 timesteps with reward=8.0\n",
      "Episode finished after 138 timesteps with reward=14.0\n",
      "Episode finished after 70 timesteps with reward=4.0\n",
      "Episode finished after 177 timesteps with reward=9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:21:11,626] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      "  5%|▌         | 100/2000 [00:42<1:32:36,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 147 timesteps with reward=17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 110/2000 [00:44<10:51,  2.90it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=110\tepsilon=0.598\treward/step=0.06486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 120/2000 [00:47<08:50,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=120\tepsilon=0.571\treward/step=0.06694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 130/2000 [00:50<08:42,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=130\tepsilon=0.546\treward/step=0.06718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 140/2000 [00:53<08:47,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=140\tepsilon=0.522\treward/step=0.06879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 149/2000 [00:55<08:33,  3.61it/s][2017-06-27 00:21:25,057] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:21:25,061] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=150\tepsilon=0.499\treward/step=0.06887\n",
      "Episode finished after 87 timesteps with reward=6.0\n",
      "Episode finished after 100 timesteps with reward=7.0\n",
      "Episode finished after 76 timesteps with reward=6.0\n",
      "Episode finished after 140 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:21:32,216] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      "  8%|▊         | 150/2000 [01:02<1:15:11,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 98 timesteps with reward=10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 160/2000 [01:05<10:53,  2.82it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=160\tepsilon=0.477\treward/step=0.07019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 170/2000 [01:08<09:01,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=170\tepsilon=0.456\treward/step=0.07193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 180/2000 [01:11<08:53,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=180\tepsilon=0.436\treward/step=0.07182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 190/2000 [01:14<08:56,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=190\tepsilon=0.417\treward/step=0.07173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 199/2000 [01:16<08:43,  3.44it/s][2017-06-27 00:21:46,502] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:21:46,507] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=200\tepsilon=0.399\treward/step=0.07264\n",
      "Episode finished after 111 timesteps with reward=9.0\n",
      "Episode finished after 122 timesteps with reward=11.0\n",
      "Episode finished after 84 timesteps with reward=9.0\n",
      "Episode finished after 65 timesteps with reward=7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:21:54,630] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 10%|█         | 200/2000 [01:25<1:22:28,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 181 timesteps with reward=15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 210/2000 [01:28<11:22,  2.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=210\tepsilon=0.382\treward/step=0.07346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 220/2000 [01:31<09:53,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=220\tepsilon=0.366\treward/step=0.07466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 230/2000 [01:34<10:01,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=230\tepsilon=0.351\treward/step=0.07489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 240/2000 [01:38<10:05,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=240\tepsilon=0.336\treward/step=0.07552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 249/2000 [01:41<09:54,  2.95it/s][2017-06-27 00:22:10,749] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:22:10,758] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=250\tepsilon=0.322\treward/step=0.07689\n",
      "Episode finished after 82 timesteps with reward=8.0\n",
      "Episode finished after 128 timesteps with reward=16.0\n",
      "Episode finished after 97 timesteps with reward=9.0\n",
      "Episode finished after 65 timesteps with reward=4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:22:16,867] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 12%|█▎        | 250/2000 [01:47<1:03:55,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 54 timesteps with reward=4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 260/2000 [01:51<12:16,  2.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=260\tepsilon=0.309\treward/step=0.07893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 270/2000 [01:54<10:26,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=270\tepsilon=0.296\treward/step=0.07934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 280/2000 [01:58<10:25,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=280\tepsilon=0.284\treward/step=0.07865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 290/2000 [02:01<10:22,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=290\tepsilon=0.273\treward/step=0.07835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 299/2000 [02:04<10:14,  2.77it/s][2017-06-27 00:22:34,670] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:22:34,675] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=300\tepsilon=0.262\treward/step=0.07833\n",
      "Episode finished after 62 timesteps with reward=7.0\n",
      "Episode finished after 116 timesteps with reward=12.0\n",
      "Episode finished after 121 timesteps with reward=11.0\n",
      "Episode finished after 172 timesteps with reward=18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:22:43,929] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 15%|█▌        | 300/2000 [02:14<1:29:24,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 176 timesteps with reward=18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 310/2000 [02:18<12:08,  2.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=310\tepsilon=0.252\treward/step=0.07867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 320/2000 [02:21<10:08,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=320\tepsilon=0.242\treward/step=0.07967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 330/2000 [02:25<09:56,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=330\tepsilon=0.232\treward/step=0.08100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 340/2000 [02:28<09:55,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=340\tepsilon=0.224\treward/step=0.07967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 349/2000 [02:31<09:37,  2.86it/s][2017-06-27 00:23:01,253] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:23:01,258] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=350\tepsilon=0.215\treward/step=0.08100\n",
      "Episode finished after 143 timesteps with reward=15.0\n",
      "Episode finished after 142 timesteps with reward=13.0\n",
      "Episode finished after 153 timesteps with reward=15.0\n",
      "Episode finished after 96 timesteps with reward=8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:23:10,253] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 18%|█▊        | 350/2000 [02:41<1:24:17,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 92 timesteps with reward=10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 360/2000 [02:44<11:58,  2.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=360\tepsilon=0.207\treward/step=0.08233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 370/2000 [02:48<09:45,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=370\tepsilon=0.199\treward/step=0.08233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 380/2000 [02:51<09:42,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=380\tepsilon=0.192\treward/step=0.08500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 390/2000 [02:55<09:38,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=390\tepsilon=0.185\treward/step=0.08667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 399/2000 [02:58<09:13,  2.89it/s][2017-06-27 00:23:27,788] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:23:27,794] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=400\tepsilon=0.179\treward/step=0.08667\n",
      "Episode finished after 156 timesteps with reward=14.0\n",
      "Episode finished after 166 timesteps with reward=15.0\n",
      "Episode finished after 106 timesteps with reward=12.0\n",
      "Episode finished after 129 timesteps with reward=16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:23:37,743] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 20%|██        | 400/2000 [03:08<1:29:16,  3.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 138 timesteps with reward=12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 410/2000 [03:11<11:55,  2.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=410\tepsilon=0.172\treward/step=0.08700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 420/2000 [03:15<09:29,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=420\tepsilon=0.166\treward/step=0.08733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 430/2000 [03:18<09:20,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=430\tepsilon=0.161\treward/step=0.08833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 440/2000 [03:22<09:22,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=440\tepsilon=0.155\treward/step=0.08800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 449/2000 [03:25<09:03,  2.86it/s][2017-06-27 00:23:55,269] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:23:55,274] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=450\tepsilon=0.150\treward/step=0.08867\n",
      "Episode finished after 129 timesteps with reward=12.0\n",
      "Episode finished after 320 timesteps with reward=24.0\n",
      "Episode finished after 159 timesteps with reward=13.0\n",
      "Episode finished after 179 timesteps with reward=18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:24:08,418] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 22%|██▎       | 450/2000 [03:39<1:51:25,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 139 timesteps with reward=15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 460/2000 [03:42<12:18,  2.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=460\tepsilon=0.145\treward/step=0.08867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 470/2000 [03:46<09:14,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=470\tepsilon=0.141\treward/step=0.08833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 480/2000 [03:49<09:03,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=480\tepsilon=0.136\treward/step=0.08800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 490/2000 [03:53<09:02,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=490\tepsilon=0.132\treward/step=0.08900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 499/2000 [03:56<08:44,  2.86it/s][2017-06-27 00:24:25,969] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:24:25,974] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=500\tepsilon=0.128\treward/step=0.08933\n",
      "Episode finished after 120 timesteps with reward=15.0\n",
      "Episode finished after 118 timesteps with reward=13.0\n",
      "Episode finished after 70 timesteps with reward=9.0\n",
      "Episode finished after 167 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:24:34,633] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 25%|██▌       | 500/2000 [04:05<1:14:04,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 129 timesteps with reward=14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 510/2000 [04:08<10:44,  2.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=510\tepsilon=0.124\treward/step=0.09000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 520/2000 [04:12<08:54,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=520\tepsilon=0.121\treward/step=0.09000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 530/2000 [04:15<08:51,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=530\tepsilon=0.117\treward/step=0.09133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 540/2000 [04:19<08:47,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=540\tepsilon=0.114\treward/step=0.09133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 549/2000 [04:22<08:30,  2.84it/s][2017-06-27 00:24:52,074] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:24:52,079] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=550\tepsilon=0.111\treward/step=0.09067\n",
      "Episode finished after 141 timesteps with reward=18.0\n",
      "Episode finished after 175 timesteps with reward=19.0\n",
      "Episode finished after 92 timesteps with reward=11.0\n",
      "Episode finished after 83 timesteps with reward=9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:25:00,761] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 28%|██▊       | 550/2000 [04:31<1:11:58,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 112 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 560/2000 [04:34<10:22,  2.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=560\tepsilon=0.108\treward/step=0.08967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 570/2000 [04:38<08:34,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=570\tepsilon=0.105\treward/step=0.09033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 580/2000 [04:41<08:29,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=580\tepsilon=0.102\treward/step=0.09100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 590/2000 [04:45<08:26,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=590\tepsilon=0.100\treward/step=0.09200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 599/2000 [04:48<08:06,  2.88it/s][2017-06-27 00:25:18,151] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:25:18,155] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=600\tepsilon=0.097\treward/step=0.09300\n",
      "Episode finished after 105 timesteps with reward=12.0\n",
      "Episode finished after 83 timesteps with reward=7.0\n",
      "Episode finished after 87 timesteps with reward=12.0\n",
      "Episode finished after 165 timesteps with reward=17.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:25:26,759] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 30%|███       | 600/2000 [04:57<1:08:43,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 158 timesteps with reward=15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 610/2000 [05:00<10:05,  2.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=610\tepsilon=0.095\treward/step=0.09333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 620/2000 [05:04<08:18,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=620\tepsilon=0.093\treward/step=0.09233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 630/2000 [05:07<08:06,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=630\tepsilon=0.091\treward/step=0.09000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 640/2000 [05:11<08:12,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=640\tepsilon=0.089\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 649/2000 [05:14<07:54,  2.84it/s][2017-06-27 00:25:44,260] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:25:44,265] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=650\tepsilon=0.087\treward/step=0.09267\n",
      "Episode finished after 116 timesteps with reward=16.0\n",
      "Episode finished after 119 timesteps with reward=12.0\n",
      "Episode finished after 226 timesteps with reward=16.0\n",
      "Episode finished after 85 timesteps with reward=11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:25:53,534] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 32%|███▎      | 650/2000 [05:24<1:10:50,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 101 timesteps with reward=9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 660/2000 [05:27<10:03,  2.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=660\tepsilon=0.085\treward/step=0.09367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 670/2000 [05:31<07:59,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=670\tepsilon=0.083\treward/step=0.09367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 680/2000 [05:34<07:52,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=680\tepsilon=0.082\treward/step=0.09333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 690/2000 [05:38<07:52,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=690\tepsilon=0.080\treward/step=0.09300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 699/2000 [05:41<07:34,  2.86it/s][2017-06-27 00:26:11,181] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:26:11,186] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=700\tepsilon=0.079\treward/step=0.09333\n",
      "Episode finished after 96 timesteps with reward=11.0\n",
      "Episode finished after 155 timesteps with reward=19.0\n",
      "Episode finished after 193 timesteps with reward=21.0\n",
      "Episode finished after 89 timesteps with reward=9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:26:20,775] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 35%|███▌      | 700/2000 [05:51<1:10:19,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 137 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 710/2000 [05:54<09:29,  2.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=710\tepsilon=0.077\treward/step=0.09400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 720/2000 [05:58<07:50,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=720\tepsilon=0.076\treward/step=0.09433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 730/2000 [06:02<07:39,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=730\tepsilon=0.075\treward/step=0.09433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 740/2000 [06:05<07:34,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=740\tepsilon=0.073\treward/step=0.09433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 749/2000 [06:08<07:12,  2.89it/s][2017-06-27 00:26:38,268] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:26:38,273] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=750\tepsilon=0.072\treward/step=0.09367\n",
      "Episode finished after 143 timesteps with reward=15.0\n",
      "Episode finished after 127 timesteps with reward=10.0\n",
      "Episode finished after 208 timesteps with reward=22.0\n",
      "Episode finished after 151 timesteps with reward=15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:26:49,429] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 38%|███▊      | 750/2000 [06:20<1:17:21,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 151 timesteps with reward=19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 760/2000 [06:23<09:42,  2.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=760\tepsilon=0.071\treward/step=0.09467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 770/2000 [06:27<07:42,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=770\tepsilon=0.070\treward/step=0.09400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 780/2000 [06:30<07:23,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=780\tepsilon=0.069\treward/step=0.09567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 790/2000 [06:34<07:14,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=790\tepsilon=0.068\treward/step=0.09600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 799/2000 [06:37<07:01,  2.85it/s][2017-06-27 00:27:07,263] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:27:07,267] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=800\tepsilon=0.067\treward/step=0.09567\n",
      "Episode finished after 114 timesteps with reward=13.0\n",
      "Episode finished after 124 timesteps with reward=16.0\n",
      "Episode finished after 90 timesteps with reward=8.0\n",
      "Episode finished after 118 timesteps with reward=15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:27:15,322] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 40%|████      | 800/2000 [06:46<55:42,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 110 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 810/2000 [06:49<08:35,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=810\tepsilon=0.067\treward/step=0.09600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 820/2000 [06:53<07:14,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=820\tepsilon=0.066\treward/step=0.09633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 830/2000 [06:56<07:04,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=830\tepsilon=0.065\treward/step=0.09600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 840/2000 [07:00<07:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=840\tepsilon=0.064\treward/step=0.09667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 849/2000 [07:03<06:37,  2.89it/s][2017-06-27 00:27:32,867] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:27:32,872] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=850\tepsilon=0.064\treward/step=0.09700\n",
      "Episode finished after 74 timesteps with reward=6.0\n",
      "Episode finished after 138 timesteps with reward=14.0\n",
      "Episode finished after 103 timesteps with reward=11.0\n",
      "Episode finished after 116 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:27:40,892] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 42%|████▎     | 850/2000 [07:11<53:08,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 117 timesteps with reward=15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 860/2000 [07:15<08:21,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=860\tepsilon=0.063\treward/step=0.09733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 870/2000 [07:18<06:48,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=870\tepsilon=0.062\treward/step=0.09667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 880/2000 [07:22<06:42,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=880\tepsilon=0.062\treward/step=0.09767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 890/2000 [07:25<06:40,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=890\tepsilon=0.061\treward/step=0.09733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 899/2000 [07:28<06:23,  2.87it/s][2017-06-27 00:27:58,553] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:27:58,558] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=900\tepsilon=0.061\treward/step=0.09700\n",
      "Episode finished after 112 timesteps with reward=12.0\n",
      "Episode finished after 119 timesteps with reward=12.0\n",
      "Episode finished after 112 timesteps with reward=14.0\n",
      "Episode finished after 59 timesteps with reward=6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:28:06,753] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 45%|████▌     | 900/2000 [07:37<51:47,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 164 timesteps with reward=23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 910/2000 [07:40<07:47,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=910\tepsilon=0.060\treward/step=0.09800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 920/2000 [07:44<06:27,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=920\tepsilon=0.060\treward/step=0.09867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 930/2000 [07:47<06:24,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=930\tepsilon=0.059\treward/step=0.10133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 940/2000 [07:51<06:19,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=940\tepsilon=0.059\treward/step=0.10100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 949/2000 [07:54<06:06,  2.87it/s][2017-06-27 00:28:24,166] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:28:24,171] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=950\tepsilon=0.058\treward/step=0.09933\n",
      "Episode finished after 89 timesteps with reward=11.0\n",
      "Episode finished after 98 timesteps with reward=12.0\n",
      "Episode finished after 124 timesteps with reward=15.0\n",
      "Episode finished after 102 timesteps with reward=11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:28:31,696] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 48%|████▊     | 950/2000 [08:02<45:54,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 105 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 960/2000 [08:06<07:31,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=960\tepsilon=0.058\treward/step=0.09867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 970/2000 [08:09<06:14,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=970\tepsilon=0.057\treward/step=0.09833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 980/2000 [08:13<06:07,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=980\tepsilon=0.057\treward/step=0.09733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 990/2000 [08:16<06:02,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=990\tepsilon=0.057\treward/step=0.09700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 999/2000 [08:19<05:44,  2.91it/s][2017-06-27 00:28:49,344] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:28:49,348] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1000\tepsilon=0.056\treward/step=0.09700\n",
      "Episode finished after 185 timesteps with reward=23.0\n",
      "Episode finished after 145 timesteps with reward=17.0\n",
      "Episode finished after 117 timesteps with reward=11.0\n",
      "Episode finished after 97 timesteps with reward=10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:28:58,826] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 50%|█████     | 1000/2000 [08:29<53:28,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 113 timesteps with reward=12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1010/2000 [08:33<07:15,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1010\tepsilon=0.056\treward/step=0.09633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1020/2000 [08:36<05:56,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1020\tepsilon=0.056\treward/step=0.09600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1030/2000 [08:40<05:48,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1030\tepsilon=0.056\treward/step=0.09633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1040/2000 [08:43<05:44,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1040\tepsilon=0.055\treward/step=0.09667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1049/2000 [08:46<05:30,  2.88it/s][2017-06-27 00:29:16,280] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:29:16,285] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1050\tepsilon=0.055\treward/step=0.09733\n",
      "Episode finished after 201 timesteps with reward=22.0\n",
      "Episode finished after 141 timesteps with reward=13.0\n",
      "Episode finished after 126 timesteps with reward=14.0\n",
      "Episode finished after 109 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:29:25,504] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 52%|█████▎    | 1050/2000 [08:56<49:35,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 64 timesteps with reward=6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1060/2000 [08:59<06:55,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1060\tepsilon=0.055\treward/step=0.09633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 1070/2000 [09:03<05:40,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1070\tepsilon=0.055\treward/step=0.09767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1080/2000 [09:06<05:32,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1080\tepsilon=0.054\treward/step=0.09667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1090/2000 [09:10<05:26,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1090\tepsilon=0.054\treward/step=0.09633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1099/2000 [09:13<05:18,  2.83it/s][2017-06-27 00:29:43,079] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:29:43,084] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1100\tepsilon=0.054\treward/step=0.09667\n",
      "Episode finished after 174 timesteps with reward=22.0\n",
      "Episode finished after 116 timesteps with reward=9.0\n",
      "Episode finished after 107 timesteps with reward=12.0\n",
      "Episode finished after 99 timesteps with reward=12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:29:51,746] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 55%|█████▌    | 1100/2000 [09:22<44:32,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 103 timesteps with reward=12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1110/2000 [09:26<06:31,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1110\tepsilon=0.054\treward/step=0.09533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1120/2000 [09:29<05:22,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1120\tepsilon=0.054\treward/step=0.09467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1130/2000 [09:33<05:15,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1130\tepsilon=0.053\treward/step=0.09333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1140/2000 [09:36<05:13,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1140\tepsilon=0.053\treward/step=0.09200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1149/2000 [09:39<04:56,  2.87it/s][2017-06-27 00:30:09,342] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:30:09,346] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1150\tepsilon=0.053\treward/step=0.09267\n",
      "Episode finished after 66 timesteps with reward=8.0\n",
      "Episode finished after 167 timesteps with reward=19.0\n",
      "Episode finished after 157 timesteps with reward=12.0\n",
      "Episode finished after 129 timesteps with reward=15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:30:19,000] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 57%|█████▊    | 1150/2000 [09:49<46:17,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 150 timesteps with reward=15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1160/2000 [09:53<06:27,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1160\tepsilon=0.053\treward/step=0.09233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1170/2000 [09:56<05:02,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1170\tepsilon=0.053\treward/step=0.09200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1180/2000 [10:00<04:56,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1180\tepsilon=0.053\treward/step=0.09133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 1190/2000 [10:03<04:49,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1190\tepsilon=0.052\treward/step=0.09133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 1199/2000 [10:07<04:39,  2.87it/s][2017-06-27 00:30:36,733] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:30:36,737] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1200\tepsilon=0.052\treward/step=0.09033\n",
      "Episode finished after 97 timesteps with reward=13.0\n",
      "Episode finished after 107 timesteps with reward=11.0\n",
      "Episode finished after 187 timesteps with reward=20.0\n",
      "Episode finished after 94 timesteps with reward=9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:30:46,479] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 60%|██████    | 1200/2000 [10:17<43:49,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 190 timesteps with reward=23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1210/2000 [10:20<05:48,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1210\tepsilon=0.052\treward/step=0.08833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1220/2000 [10:24<04:39,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1220\tepsilon=0.052\treward/step=0.08767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1230/2000 [10:27<04:37,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1230\tepsilon=0.052\treward/step=0.08767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1240/2000 [10:31<04:31,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1240\tepsilon=0.052\treward/step=0.08700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1249/2000 [10:34<04:20,  2.88it/s][2017-06-27 00:31:03,858] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:31:03,863] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1250\tepsilon=0.052\treward/step=0.08833\n",
      "Episode finished after 94 timesteps with reward=9.0\n",
      "Episode finished after 53 timesteps with reward=5.0\n",
      "Episode finished after 120 timesteps with reward=11.0\n",
      "Episode finished after 157 timesteps with reward=16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:31:12,826] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 62%|██████▎   | 1250/2000 [10:43<38:11,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 200 timesteps with reward=21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1260/2000 [10:47<05:21,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1260\tepsilon=0.052\treward/step=0.08900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 1270/2000 [10:50<04:26,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1270\tepsilon=0.052\treward/step=0.09033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1280/2000 [10:54<04:18,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1280\tepsilon=0.052\treward/step=0.09000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1290/2000 [10:57<04:17,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1290\tepsilon=0.052\treward/step=0.09100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 1299/2000 [11:00<04:04,  2.86it/s][2017-06-27 00:31:30,358] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:31:30,362] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1300\tepsilon=0.051\treward/step=0.09067\n",
      "Episode finished after 105 timesteps with reward=10.0\n",
      "Episode finished after 126 timesteps with reward=13.0\n",
      "Episode finished after 88 timesteps with reward=10.0\n",
      "Episode finished after 131 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:31:38,623] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 65%|██████▌   | 1300/2000 [11:09<33:16,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 124 timesteps with reward=11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1310/2000 [11:12<04:58,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1310\tepsilon=0.051\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1320/2000 [11:16<04:07,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1320\tepsilon=0.051\treward/step=0.09200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 1330/2000 [11:19<04:02,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1330\tepsilon=0.051\treward/step=0.09133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1340/2000 [11:23<03:55,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1340\tepsilon=0.051\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1349/2000 [11:26<03:46,  2.88it/s][2017-06-27 00:31:56,127] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:31:56,132] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1350\tepsilon=0.051\treward/step=0.09167\n",
      "Episode finished after 95 timesteps with reward=11.0\n",
      "Episode finished after 217 timesteps with reward=25.0\n",
      "Episode finished after 135 timesteps with reward=16.0\n",
      "Episode finished after 59 timesteps with reward=6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:32:04,860] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 68%|██████▊   | 1350/2000 [11:35<32:17,  2.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 99 timesteps with reward=10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1360/2000 [11:39<04:37,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1360\tepsilon=0.051\treward/step=0.09133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1370/2000 [11:42<03:48,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1370\tepsilon=0.051\treward/step=0.09033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1380/2000 [11:46<03:43,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1380\tepsilon=0.051\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1390/2000 [11:49<03:39,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1390\tepsilon=0.051\treward/step=0.09033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1399/2000 [11:52<03:29,  2.87it/s][2017-06-27 00:32:22,282] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:32:22,287] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1400\tepsilon=0.051\treward/step=0.09033\n",
      "Episode finished after 141 timesteps with reward=14.0\n",
      "Episode finished after 111 timesteps with reward=10.0\n",
      "Episode finished after 143 timesteps with reward=17.0\n",
      "Episode finished after 136 timesteps with reward=18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:32:31,456] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 70%|███████   | 1400/2000 [12:02<31:10,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 105 timesteps with reward=12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1410/2000 [12:05<04:17,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1410\tepsilon=0.051\treward/step=0.09033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1420/2000 [12:09<03:30,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1420\tepsilon=0.051\treward/step=0.09033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1430/2000 [12:12<03:25,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1430\tepsilon=0.051\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1440/2000 [12:16<03:21,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1440\tepsilon=0.051\treward/step=0.09233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1449/2000 [12:19<03:11,  2.88it/s][2017-06-27 00:32:48,860] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:32:48,865] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1450\tepsilon=0.051\treward/step=0.09100\n",
      "Episode finished after 113 timesteps with reward=12.0\n",
      "Episode finished after 74 timesteps with reward=7.0\n",
      "Episode finished after 212 timesteps with reward=21.0\n",
      "Episode finished after 89 timesteps with reward=8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:32:57,799] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 72%|███████▎  | 1450/2000 [12:28<27:57,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 121 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1460/2000 [12:32<03:52,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1460\tepsilon=0.051\treward/step=0.09033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 1470/2000 [12:35<03:10,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1470\tepsilon=0.051\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1480/2000 [12:38<03:05,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1480\tepsilon=0.051\treward/step=0.09200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1490/2000 [12:42<03:03,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1490\tepsilon=0.051\treward/step=0.09267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 1499/2000 [12:45<02:54,  2.87it/s][2017-06-27 00:33:15,175] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:33:15,180] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1500\tepsilon=0.051\treward/step=0.09400\n",
      "Episode finished after 160 timesteps with reward=19.0\n",
      "Episode finished after 96 timesteps with reward=11.0\n",
      "Episode finished after 128 timesteps with reward=13.0\n",
      "Episode finished after 61 timesteps with reward=6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:33:22,502] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 75%|███████▌  | 1500/2000 [12:53<21:19,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 62 timesteps with reward=6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1510/2000 [12:56<03:25,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1510\tepsilon=0.050\treward/step=0.09467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1520/2000 [13:00<02:52,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1520\tepsilon=0.050\treward/step=0.09500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 1530/2000 [13:03<02:49,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1530\tepsilon=0.050\treward/step=0.09467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1540/2000 [13:07<02:45,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1540\tepsilon=0.050\treward/step=0.09633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 1549/2000 [13:10<02:35,  2.90it/s][2017-06-27 00:33:39,920] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:33:39,925] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1550\tepsilon=0.050\treward/step=0.09567\n",
      "Episode finished after 159 timesteps with reward=17.0\n",
      "Episode finished after 102 timesteps with reward=12.0\n",
      "Episode finished after 186 timesteps with reward=15.0\n",
      "Episode finished after 131 timesteps with reward=10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:33:51,657] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 78%|███████▊  | 1550/2000 [13:22<29:09,  3.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 247 timesteps with reward=25.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1560/2000 [13:26<03:26,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1560\tepsilon=0.050\treward/step=0.09533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 1570/2000 [13:29<02:36,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1570\tepsilon=0.050\treward/step=0.09467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 1580/2000 [13:33<02:32,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1580\tepsilon=0.050\treward/step=0.09467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1590/2000 [13:36<02:26,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1590\tepsilon=0.050\treward/step=0.09500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 1599/2000 [13:39<02:19,  2.87it/s][2017-06-27 00:34:09,333] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:34:09,338] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1600\tepsilon=0.050\treward/step=0.09367\n",
      "Episode finished after 100 timesteps with reward=11.0\n",
      "Episode finished after 111 timesteps with reward=14.0\n",
      "Episode finished after 107 timesteps with reward=8.0\n",
      "Episode finished after 97 timesteps with reward=12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:34:16,685] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 80%|████████  | 1600/2000 [13:47<17:05,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 97 timesteps with reward=10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 1610/2000 [13:50<02:43,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1610\tepsilon=0.050\treward/step=0.09300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 1620/2000 [13:54<02:16,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1620\tepsilon=0.050\treward/step=0.09233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1630/2000 [13:57<02:14,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1630\tepsilon=0.050\treward/step=0.09267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1640/2000 [14:01<02:09,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1640\tepsilon=0.050\treward/step=0.09233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1649/2000 [14:04<02:03,  2.85it/s][2017-06-27 00:34:34,132] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:34:34,137] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1650\tepsilon=0.050\treward/step=0.09333\n",
      "Episode finished after 170 timesteps with reward=20.0\n",
      "Episode finished after 121 timesteps with reward=14.0\n",
      "Episode finished after 72 timesteps with reward=6.0\n",
      "Episode finished after 143 timesteps with reward=14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:34:42,965] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 82%|████████▎ | 1650/2000 [14:13<17:36,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 99 timesteps with reward=10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 1660/2000 [14:17<02:31,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1660\tepsilon=0.050\treward/step=0.09333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 1670/2000 [14:20<01:58,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1670\tepsilon=0.050\treward/step=0.09300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1680/2000 [14:24<01:54,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1680\tepsilon=0.050\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 1690/2000 [14:27<01:53,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1690\tepsilon=0.050\treward/step=0.09300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 1699/2000 [14:30<01:44,  2.88it/s][2017-06-27 00:35:00,658] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:35:00,662] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1700\tepsilon=0.050\treward/step=0.09300\n",
      "Episode finished after 104 timesteps with reward=13.0\n",
      "Episode finished after 119 timesteps with reward=11.0\n",
      "Episode finished after 140 timesteps with reward=12.0\n",
      "Episode finished after 106 timesteps with reward=16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:35:09,655] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 85%|████████▌ | 1700/2000 [14:40<15:18,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 159 timesteps with reward=16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1710/2000 [14:43<02:07,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1710\tepsilon=0.050\treward/step=0.09300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 1720/2000 [14:47<01:41,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1720\tepsilon=0.050\treward/step=0.09300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 1730/2000 [14:50<01:37,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1730\tepsilon=0.050\treward/step=0.09200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1740/2000 [14:54<01:35,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1740\tepsilon=0.050\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1749/2000 [14:57<01:28,  2.84it/s][2017-06-27 00:35:27,223] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:35:27,227] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1750\tepsilon=0.050\treward/step=0.09300\n",
      "Episode finished after 146 timesteps with reward=14.0\n",
      "Episode finished after 143 timesteps with reward=14.0\n",
      "Episode finished after 79 timesteps with reward=8.0\n",
      "Episode finished after 119 timesteps with reward=15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:35:35,949] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 88%|████████▊ | 1750/2000 [15:06<12:27,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 114 timesteps with reward=13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1760/2000 [15:10<01:44,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1760\tepsilon=0.050\treward/step=0.09300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1770/2000 [15:13<01:23,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1770\tepsilon=0.050\treward/step=0.09233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1780/2000 [15:17<01:19,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1780\tepsilon=0.050\treward/step=0.09233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1790/2000 [15:20<01:16,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1790\tepsilon=0.050\treward/step=0.09100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1799/2000 [15:23<01:10,  2.85it/s][2017-06-27 00:35:53,604] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:35:53,609] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1800\tepsilon=0.050\treward/step=0.09067\n",
      "Episode finished after 156 timesteps with reward=15.0\n",
      "Episode finished after 114 timesteps with reward=11.0\n",
      "Episode finished after 128 timesteps with reward=14.0\n",
      "Episode finished after 92 timesteps with reward=12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:36:01,712] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 90%|█████████ | 1800/2000 [15:32<09:19,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 74 timesteps with reward=6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1810/2000 [15:35<01:21,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1810\tepsilon=0.050\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1820/2000 [15:39<01:04,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1820\tepsilon=0.050\treward/step=0.09067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1830/2000 [15:42<01:01,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1830\tepsilon=0.050\treward/step=0.09067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1840/2000 [15:46<00:57,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1840\tepsilon=0.050\treward/step=0.08967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1849/2000 [15:49<00:52,  2.89it/s][2017-06-27 00:36:19,144] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:36:19,149] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1850\tepsilon=0.050\treward/step=0.09033\n",
      "Episode finished after 136 timesteps with reward=13.0\n",
      "Episode finished after 132 timesteps with reward=15.0\n",
      "Episode finished after 168 timesteps with reward=21.0\n",
      "Episode finished after 120 timesteps with reward=11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:36:29,392] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 92%|█████████▎| 1850/2000 [16:00<08:35,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 135 timesteps with reward=15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1860/2000 [16:03<01:03,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1860\tepsilon=0.050\treward/step=0.09033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 1870/2000 [16:07<00:46,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1870\tepsilon=0.050\treward/step=0.08900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1880/2000 [16:10<00:43,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1880\tepsilon=0.050\treward/step=0.08967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1890/2000 [16:14<00:39,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1890\tepsilon=0.050\treward/step=0.08900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1899/2000 [16:17<00:35,  2.84it/s][2017-06-27 00:36:47,100] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:36:47,105] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1900\tepsilon=0.050\treward/step=0.09033\n",
      "Episode finished after 147 timesteps with reward=15.0\n",
      "Episode finished after 89 timesteps with reward=9.0\n",
      "Episode finished after 64 timesteps with reward=7.0\n",
      "Episode finished after 163 timesteps with reward=19.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:36:55,918] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 95%|█████████▌| 1900/2000 [16:26<05:01,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 147 timesteps with reward=16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1910/2000 [16:30<00:39,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1910\tepsilon=0.050\treward/step=0.09100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1920/2000 [16:33<00:28,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1920\tepsilon=0.050\treward/step=0.09133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 1930/2000 [16:37<00:25,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1930\tepsilon=0.050\treward/step=0.09133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1940/2000 [16:40<00:21,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1940\tepsilon=0.050\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1949/2000 [16:43<00:18,  2.81it/s][2017-06-27 00:37:13,528] Making new env: ppaquette/DoomDefendLine-v0\n",
      "[2017-06-27 00:37:13,533] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1950\tepsilon=0.050\treward/step=0.09133\n",
      "Episode finished after 150 timesteps with reward=12.0\n",
      "Episode finished after 66 timesteps with reward=8.0\n",
      "Episode finished after 85 timesteps with reward=8.0\n",
      "Episode finished after 103 timesteps with reward=14.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-27 00:37:21,367] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 98%|█████████▊| 1950/2000 [16:52<02:16,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 132 timesteps with reward=16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1960/2000 [16:55<00:17,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1960\tepsilon=0.050\treward/step=0.09167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1970/2000 [16:59<00:10,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1970\tepsilon=0.050\treward/step=0.09300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|█████████▊| 1971/2000 [16:59<00:09,  2.90it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d6296c4ce97c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/AgentNet/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n_steps, append, max_size, add_last_observation, preprocess)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Get interaction sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         observation_tensor, action_tensor, reward_tensor, _, is_alive_tensor, _ = self.interact(n_steps=n_steps,\n\u001b[0;32m--> 194\u001b[0;31m                                                                                                 add_last_observation=add_last_observation)\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mobservation_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_alive_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreceding_memory_states\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/AgentNet/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36minteract\u001b[0;34m(self, n_steps, verbose, add_last_observation)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_last_observation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev_memory_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_memory_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/env/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/env/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    889\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/env/lib/python3.5/site-packages/theano/tensor/raw_random.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inputs, out_)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mrout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         if (not isinstance(rval, np.ndarray) or\n\u001b[1;32m    262\u001b[0m                 str(rval.dtype) != node.outputs[1].type.dtype):\n",
      "\u001b[0;32m/home/ubuntu/env/lib/python3.5/site-packages/theano/tensor/raw_random.py\u001b[0m in \u001b[0;36mchoice_helper\u001b[0;34m(random_state, a, replace, p, size)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p.ndim (%i) must be 1'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "for i in trange(2000):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    pool.update(SEQ_LENGTH, append=True)\n",
    "    \n",
    "    loss = train_step()\n",
    "    \n",
    "    targetnet.load_weights(0.01)\n",
    "    \n",
    "    ##update resolver's epsilon (chance of random action instead of optimal one)\n",
    "    current_epsilon = 0.05 + 0.95*np.exp(-epoch_counter/200.)\n",
    "    action_layer.epsilon.set_value(np.float32(current_epsilon))\n",
    "    \n",
    "    if epoch_counter%10==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = pool.experience_replay.rewards.get_value().mean()\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\"%(epoch_counter,\n",
    "                                                         current_epsilon,\n",
    "                                                         pool_mean_reward))\n",
    "        \n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%50 ==0:\n",
    "        rewards[epoch_counter] = pool.evaluate(5, record_video=False)\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results\n",
    " * Here we plot learning curves and sample testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0e69358b00>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e75c25dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time,rw = zip(*sorted(list(rewards.items()),key=lambda p:p[0]))\n",
    "plt.plot(time,list(map(np.mean,rw)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "tmp = GAME_NAME.split('/')[1]\n",
    "#os.mkdir(tmp)\n",
    "with open('{}/distilled_single'.format(tmp), 'w') as outp:\n",
    "    for idx in range(len(time)):\n",
    "        print(time[idx], rw[idx], file=outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_layer.epsilon.set_value(0.001)\n",
    "rw = pool.evaluate(n_games=100,save_path=\"./records\",record_video=True)\n",
    "print(\"mean session score=%f\"%np.mean(rw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gym.scoreboard.api_key = 'sk_X6PO6hv9Rq24jaL21xROSA'\n",
    "#gym.upload('/home/ubuntu/records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.utils.persistence import save,load\n",
    "#save for display\n",
    "save(action_layer,\"{}/distilled_single.pcl\".format(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "from random import choice\n",
    "#select the one you want\n",
    "videos = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "video_path=\"./records/\"+choice(videos)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get serious\n",
    "\n",
    "* Switch to DoomDefendCenter, DoomHealthGathering, DoomDeathmatch or similar\n",
    "* Deploy a better RL algorithm\n",
    "* Deploy a better network. Doom will likely need some recurrent nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
