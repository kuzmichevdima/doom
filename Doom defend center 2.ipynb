{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[this demo requires doom installed either from gym-pool or from [ppaquette's repo](https://github.com/ppaquette/gym-doom)]\n",
    "\n",
    "## Basic Doom demo\n",
    "\n",
    "* This demo solves DoomBasic env with a simple q-learning with experience replay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cuda,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%env THEANO_FLAGS=device=cuda,floatX=float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: Tesla K80 (0000:00:1E.0)\n",
      "[2017-06-26 21:58:27,179] Making new env: ppaquette/DoomDefendCenter-v0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ppaquette_gym_doom\n",
    "from gym.wrappers import SkipWrapper\n",
    "from ppaquette_gym_doom.wrappers.action_space import ToDiscrete\n",
    "from agentnet.experiments.openai_gym.wrappers import PreprocessImage\n",
    "GAME_NAME = 'ppaquette/DoomDefendCenter-v0'\n",
    "\n",
    "make_env = lambda: PreprocessImage(SkipWrapper(4)(ToDiscrete(\"minimal\")(gym.make(GAME_NAME))),\n",
    "                                   width=80,height=80,grayscale=True)\n",
    "\n",
    "env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "observation_shape = env.observation_space.shape\n",
    "n_actions = env.action_space.n\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "N_AGENTS = 1\n",
    "SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff69819fcf8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztfWusZlWZ5rMoQLlWUUVZFBRQVUDAsqUKhjAazYjaGOwx\nOkZCdHqM45j4p2dixzZe+sdkxkwn3X9s/TExIWKPbexWx9a0IR16lIa0LYrC4BWsKeRWRRVV3EtQ\nUGDNj/O9+zzfd573vGt/59R36tR+n6RS6+xv73Xbl/Ws91pqrUgkEsPCcSvdgUQiMXvki59IDBD5\n4icSA0S++InEAJEvfiIxQOSLn0gMEPniJxIDxJJe/FLKNaWU3aWUe0spH1+uTiUSiSOLMq0BTyll\nDYD/B+BqAPsA/BDAe2qtdy9f9xKJxJHA8Uu49koA99Za7wOAUsqXAbwDgPvil1LSTDCROMKotZbo\nnKW8+OcA2Et/7wPwr8MGj59rUjENj32UUhb8bse8OrzfVVtcPu64+d2P1fHSSy8tWhdfw4iu4z5y\n2a7jY9HYvd9b54PP8fpt44zGpa6Z7GPENPvcv2nudct8LLVfCt58qDqiZ5zPsXvSyuCX8uI3oZTy\nQQAfPNLtJBKJdizlxX8YwLn095bRsTHUWq8HcD0wR/VffPFFjMpj/0+CV5XoXPVF77NCclm168Gu\nszG19NHrl7qO+6Kua5k7tXpEffTmIGJpi61ELdctdTVtOVcdb3mu1DE1p954+8xH1BZj8n1qxVKk\n+j8EcFEpZVsp5UQA7wbwzSXUl0gkZoSpV/xa6wullP8M4B8BrAHw+Vrrz3tcD8BfidReqOWLr+QB\n3h5etau+yHyN+t3rlxpDn32710e7rmW/2FpX3zqieqfZQ3vXT7saLnZui+whekajuVPXtTCRNWvW\nNNXP9Ub1T2JJe/xa6z8A+Iel1JFIJGaPtNxLJAaIIy7VZ5RSOnWeCSVahGmR4Cui74xIyBZtMVS9\nLfRvGjraZwxef5RQqeW6qI/qmiUYgy3aVh91blTXYvV753pQW8Bpn+FIBRs9V7MU7iUSiVWKfPET\niQFiplR/7dq1uOqqqwAA+/btAwA8/PC86v+JJ57oyr/97W8XrcuTxEdUvI/VmWE59MdLba+Vwk5b\nv9fGtO0t57nR733uv6qzz3xMqwWJLOsibcKJJ57YldeuXduVzz13zpRm69atAICbb765qT+54icS\nA0S++InEADFTqn/yySfj8ssvBwDs2rULAPD88893vzPVv/feexeUn3zyye7Yr3/9667MJrMRpjGU\n6SP1Xaq0edq6lsOppY8562LXeNf1Marq06/o/ky7TZrGGCySvvM1XD7ppJO68oYNGwAAW7Zs6Y5t\n27atK2/evLkrn3LKKQDmnd++973vLT4oa7vprEQicUxhxfT4v/vd7wCMCy3OO+88Wb7yyisBjK/4\nBw8e7Mr3339/V96/f/+CcxUjaFnFl2p22sekk9GqE+5jM9BiKjxNvR6W6v56tCKaR/7dnnVgXiB3\n9tlnd8e2b9/elc8///yuvH79+gXtembjVrbfW+c7V/xEYoDIFz+RGCBmSvVrrR3FV/p0pinmoQQA\np59+OoA54aCBKdPOnTu7sgkL77vvvu7Ygw8+2JX37p0LGvT44493x9hmoA89n8ZrrA+N7hPBZxZ6\n82mEnS1bhWhrs1ST2z7mv9H1TLlf9rKXdeWNGzcCAC644ILu2FlnndWVN23aBGD+WQbGn3Huwwkn\nnLCgXXtvAP1c2DPc+hzkip9IDBD54icSA8RMqT4wT5VYmm9gyq0k8Uxj+HemX6eddhqAcfq/Y8eO\nrvzcc88BAJ566qnumNF/ANizZ09XNs3BM8880x3rQ78VWvTXyqMu0hlHfVgOT75I3x71wTOtVUE8\nI4n5tLr1xc4D5mk2AJx66qkAxik7S99Zz37mmWcCmH/+JvtrY+MxvvDCC12ZNQCq31wXbzHsuD3X\nSfUTiYSLfPETiQEipPqllM8DeBuAQ7XW3xsdWw/gKwC2AngAwHW11ie9OhhGdYzmsGRTGSZMnmNg\nusOUSUltlSSWzR7NwwkALrvssq789NNPAxg3FmINwUMPPQTA9ypcauCKWZ+7nIE2oiAmy2lm26eu\nl7/85QCAdevWdcf4/rNRjVF5lsR7/VFbU37u7Bnl55qfYZba2zPUYnTFz34ftKz4/wvANRPHPg7g\n5lrrRQBuHv2dSCRWCcIVv9b6z6WUrROH3wHgqlH5CwBuBfCxPg0rIZmn11RfcT6Xv7a/+c1vAIwL\nafr4a7OzhAkgzWkCAC699NKubALCQ4cOdceMBQDjQsPHHnsMwDgjYAelSH8cCbui7Dct9gN2rpcn\noI9Jr6qrj42Dxw7UMRYU24rO94x167ai84pv10zCxsDPEq/MKjIu318Vxo3r4meYV25lL8HzqNow\n4eCRNtndVGs9MCo/AmDTlPUkEokVwJKFe3Xu8+Ru/kopHyyl3FFKuePZZ59danOJRGIZMK0e/2Ap\nZXOt9UApZTOAQ96JlVJonXPOOXVSf6oEd8A4pbJrPJql6vNoo9E6ptmmAwXG9akqXBJT6jPOOAPA\nuPCHhUN8rgkKuV22JbAtCjAfa4BjDvC5ZlfA9JDP5TaMIkYmn4sdN/SJ7mvzqGj4ZNmEXHzMdOjA\n/DyzMMz80IFx2m5bNdan8zNmZW+rqATMPHcMflaszPdBPYN8b/j6aGvD/VXX2e9Hmup/E8D7RuX3\nAfj7KetJJBIrgPDFL6X8LYDvAbi4lLKvlPIBAH8O4OpSyh4Avz/6O5FIrBK0SPXf4/z05mkaXCxA\nA0s8mX4ZpeXfme4w5VXmn1xWpo2eBsHaY5rF2wJ1DYOpqQVX4LZYf6ykujxGpptKd8v9YlmKnctm\nx4cPH5bX2Tm2LQHG587oN0d55bkxSs7n8Bgiqu9BmbMyItNmZQrsaRt4a2Jz55nW8nFrI+qr2h5M\nwupV212vP33CzwFpuZdIDBIzD71lq6jpIj2BEn8NlVCJr+Ov9KRloLVrsBWqJb6+fXE94Y/Sp3s6\n30gHHkHZOHC7LOziFdn667EpxXy8323V8RxcVF3eCsllW/09BxaDp/eOUlnx8xH5rSvm5QmgIyGc\nEgp6WXq9/irwPJmwMGJNC/rR6+xEInFMIF/8RGKAmHnorUmK3+LjrYQgnrBL0SS1RYiENNw37qPa\ngngUlSmzUTHut2caa7Scdb5ePHbVLiMynVVmp1FE1xaouWHwPNozwe3yfbQ584RdXJcJKz1hWJ+o\nv1avt0VR9gGRwK7FH9/KPAZvuzlZV/rjJxIJF/niJxIDxMxDbxmUR5Tn2WRooTF2HUs5lU2AR7OU\nP71HsxVFZSg9vGeaqSggU8nIe4+h6Gy0rQDmtxael6TRby+TsdIceNJ3Jd32osqqvnhbl1Y9umeG\nqzRAPB+eR6XV5/Wlj55dbZO4XhV6y0y+k+onEgkX+eInEgPEilF9RUn6RHflrYIKbuGZ4SoDD65f\n0VWuP9IaeB5Xir57NNjOiehhnxBaXogzprzKw4vrsv56WxsldV+OHIXWL9VXQG+pvOdHZa31DMPs\nWeJnInquIi0IX88JYngLYWVv26L60DdHYa74icQAMXM9/qSPs1rpAP1V877MDOXQwzB/bV49+Gsb\nhbNSTjy8MnO93AflHBK15QkdI3NYrkv1kaEYjheqTJmuerp1Y0aeMEytwl5d0Sqt9PSeIFCNxbOB\nsDYiGwlgnoGyP766p56NhNc3de5Kht5KJBKrGPniJxIDxMy984ySRPpWJchhihNRW4aKf+7FRGea\npdJ9sf+6imDrUUxFwSLPNdUXQHsgRnXxvHhmxSpsGcPO9QRrKhJs9DswP7/e1mayf5N1RVGUI3od\nefJ586yeIc+Tz+DZD0TgdtWWWAlTF0Ou+InEAJEvfiIxQLSk0DoXwF9jLnZ+BXB9rfUz06bRmpTq\ne6GImF4p2hhRrokxLGjfo3dKD8u0MwrEoTzFgHmpL1O9KHqrCuQxWTZ4Wx+DR98j6uu1YeiTQddr\nQ82D2gp6XnaR2TGbuNrvnkRdzbm3LVXPnaepUabkkScfPz+e+Xa0ZfbQctdeAPAntdYdAF4D4I9K\nKTuQabQSiVWLlmCbBwAcGJV/VUq5B8A5mCKNVimlW13ty+olmVRfOM/ijL96Vj/rU5XftJd4UOma\nPYGN6pfnaKT8pT29tLLcU6wiCpHFdbE+ncfDbEetlgwVU0DZNQDaGcoTVtrKpu7TZB2GSAfO/fLs\nNBY7xn3sM88e41NWj16QUJWTgKGeN5v7I+KkM8qhdxmA25FptBKJVYvmF7+UciqAvwPwx7XWw/zb\nYmm0MoVWInH0oUkyUEo5AXMv/ZdqrV8fHW5KozWZQmux6LqRvzbD8wk32sY0SZnURqGbAE15o5BR\nntDRqJ5K0TUJpRNWvt8eRVXOTlFdPI5Ij+8JGpVgzNtSeXM22dZkHeqYp99X9du5fJ89+q5Cr3mC\nXjVnnnOPwbMPUH2JQm/1CYsGtGXSKQBuAHBPrfVT9FOm0UokVilaVvzXAXgvgJ+WUn40OvanmEub\n9dVRSq0HAVx3ZLqYSCSWGy1S/X8B4NkB9k6jZZRHJQCIQm8xnYlMIyMa7Pnjs59/lMpIpevyIv4a\nVfOkukqq79HoSY8swJ+7yCZA+el7JshqziOpfUtkXGsvOjd6PhjedkalJ/N86NX2LDJ9njbdl5LU\nezEW+LmazMKbobcSiYSLfPETiQFixUJvqRx2kaEE006m5GygYdJaj3LZca7f0xBEtElJwfsEdejj\nUdfHO09pMby2+Fy1LYjCeHneiNZHL+QXz7mN06O+aj684CdKEh9ltfWClKgAMFGWXW9LZeAxeFmY\n1RYjCkXXF7niJxIDxMxDb9kXU6U6ioIL8pebV3l1rgcVG94z/1VmmBa/HNCrofeVVma2nnCv1afa\nWwW8VUnVr1iDt7JGTjqq3RZhZsSsopz2kc1HJEhksOCsVbg7WVZ9UeHFIpNshgoCCiyM/Z/++IlE\nwkW++InEALFiobf6hChSUVY9GE31aKVtMTx/bobKcNoaAx4Yp2RRvxTVU2G+uC5PwKWEb57Qie0p\nlDkzw/rljUEJzFpi4attH9+TKFa+qsvz9ItCXylPTW8+polP0JJbQGWS9uZu8vqk+olEwkW++InE\nADFzPf6kF5EXPVQFUogijfJ1nilpn5BOUSAO5RHlRew1LYLn2aZMTD0NQR/vvAhKhx3RUa/dKOWX\np9FQthVRkowoKItXV+SByLD2PA2Eeh5VgBGuy9uiKA9D1iB5HoiTmpik+olEwkW++InEADFzqf5i\nMfeY+ngSXoNHz60Oz6hDeVFx/SoQhxeR1+L6teT/U2aYUZTdiK56xjMMtU3xaK7yNoyCYHh1WbvR\nfZo8R/U7yq2n6vIouZVZ4+J5fdq95t/5+VD99bRFSkMUeVSyxsXzILT+qPoXQ674icQAMXOTXftq\nR/HvI/D1SnfqxcpXOmFeEfgra20ohxJuw/PHV8I5b3VRprGefYHKie4JviZNOoHYNz+yNYhSXfG5\nHjtQ88R1KQFWS7ZcNS71u+eks1gEW2D8+VAm5FHcfO9ZieI8RJmi02Q3kUiEyBc/kRggZq7Hnwx9\n5Jm4RjTJC52kaJ2iq55u1hOiTFOX8r7yxsDnqii7kT++FxLKaD1vfTyhoLXneef1iQOghJkq5gC3\n6/nQ29x5STa8cFYKyh/fE1D28ce3dr3kLCqsmTKXBubfA2+bpEJvLRa9WqElyu7LSyk/KKX8uJTy\n81LKfx8d31ZKub2Ucm8p5SulFJ32I5FIHHVoofrPA3hTrXUngF0ArimlvAbAXwD4y1rrhQCeBPCB\nI9fNRCKxnGiJslsBPDP684TRvwrgTQD+/ej4FwD8NwCfjeqbTHgRJW8ANBXk0FssDVbmvYyTTjoJ\ngKZWk9dZmY+pnHye7pb7pUIzeXp8laPOiwps8EJ+2bncl0jX7FFMtbWJEl94/VL2DDwuJT339Pgq\nWy7/ztTY5sGbD/VceUlWVBgtfj6iJBueTUcUsVdtc1uj6xqahHullDWjmPqHAHwLwC8BPFVrtbu6\nD3OJNNW1mUIrkTjK0CTcq7W+CGBXKWUdgG8AuKS1AU6hdfbZZ9dJC6PIgYbBqwd/WRmRlZ99vT09\nvtL/RsKjlmCbka657xd7sWvUyttSv7IPUPV6AqRoPB5rUauWEqJ5tgpKEBg5/HhQ2Zs9a0zFFL1z\n1TUtbMjgWQ9OWnEeET1+rfUpALcAeC2AdaUU6+EWAA/3qSuRSKwcWqT6G0crPUopJwG4GsA9mPsA\nXDs6LXPnJRKrCC1UfzOAL5RS1mDuQ/HVWuuNpZS7AXy5lPI/ANyFucSai4JDb9n/LSadylQ0ypAa\n+U17tJKh/PG9qLGqX0pf7sWZV/MQ6aT7bBW8utQ2xrNL6BMCLbJxiISVDBXyK7reC9Nl10X3nNuL\nHJEmy4boGfZsHNTWxrtuEq1Uv0Wq/xMAl4nj9wG4sqmVRCJxVCFNdhOJAWLFTHaVSadnRtmaFguY\np2qsOlRU0PP9Vzpbb9ug/PEZykPQM5dVlFtFj+XjLSasKiKvZzZs2L9/f1f+1a9+1ZUvvPDCBe2y\nFFxpaKJ0XIC2NVD3x5OCK5rtbQtsPrz5Yqi58SIfq2uUibLnYcjPih3nZ9irVyV9aUGu+InEAJEv\nfiIxQMw89JZRLaOAHhVkemZmtlHABGCeMrHppbqO2/UCLdh1HsW0cz3aqCS1LR51KhCH540Y1aW8\n89Tv3McDBw50x5ia2tbm5JNPlu1GwUS8dq1vXh+jbLmRJ5/KyOz1SwVtUcFXJs9VuRz5OiVtj7ZJ\n9txzvwEdcdl+bzUEyxU/kRggVixbrlq1vOyj3oqr0Bq2yBPIRSGO+kAJ0TyfdCWMiuLUMyJ9uecn\nrmwBzjjjjO4Yx3a3Fcyboyi/AUPpyyOHH2/V62MqrO6/N3fqGekTryG6PhJ2euNVz0UK9xKJRIh8\n8ROJAWLFUmhFobciM05PEGQCKC/tlQmmWLDi+VtH/vjKI4r7pXS+LZ5t1gdvPux3T8ClTFS9GO5c\nNr0xn8u039r14gR4YbgU+FzlQ+/ZKKjf+Tqri39nga1tXbwozZE/vjd3dt/5nimqHsUJ4PairMUM\nFT16MeSKn0gMEPniJxIDxMyp/qSXkiet7JPGiamgSoKgdOteWxEiCutJmL3AIepcQ7Td8aTR6pyW\nLL02tvXr13fHeG7MfLdPptkWRIFD+tSlKDXPvQoAw/WzFkPNndpGATrKbR+TXqUt8EzYlXmvF8bN\nQ674icQAkS9+IjFAzJTqv/TSSx2VMvrFdMmj0Sqog0dXrewZP/SJbRcFeOgT207Fq/NoowoAEW13\nvD6ofHjedSqacZ9AHdNuTSIqH409GptqKzIWYkRGSgzPMMiuU6a9Xr1eXkLWMkyOJ7PlJhIJFzN3\n0lFCva4zDWmNWuHpafusLvb19ARjEdTXt6UuxVoYi83hZL3KwcXLnKv0w166rOh3NQbPrDQyo1WI\nGIPKy9Dn+mnRJydBVEefKMpHLMruKLb+XaWUG0d/ZwqtRGKVog/V/xDmousaMoVWIrFK0UT1Sylb\nAPxbAH8G4MNljk9MlUKL6lxwrA+1ieCZ7E6jX55WJx1d54Xhsus8WwRFjb26omjGXn8UFqOYk/Wq\n9GJeLAIlNFS6c8/2Qs1TlNiCMe39VV6Kfe5/JKDu08cjRfU/DeCjAGy2N2CKFFqREUsikZgNWhJq\nvA3AoVrrndM0UGu9vtZ6Ra31Co7ckkgkVg4tVP91AN5eSvkDAC8HcDqAz2CUQmu06i9LCq2IpixV\n99u33kh/rEw6+/TR0yVHnnxKOt6SIEKd622JFJQ5LPdFZaD1zlX2AZ79gIpQ64XAmqzTG4OHKGHK\ntElB1DUtx48Uwt7WWj9Ra91Sa90K4N0A/qnW+ofIFFqJxKrFUvT4H0PPFFrAwlj1kVMDnzutPj1C\nlJqpj6WaJ+xSwh9ebaPwYJGu2lt91Bh4vOyrruD5vat2Wcim7pk3XpVeTLU7rVDS66/qy3LWq9qY\n9cruodeLX2u9FcCto3Km0EokVinSZDeRGCBmbrLbKkxq2QK0YlrhT+QcpOr30m1FULp3L4680lVH\n88p9ZMFYH+GeEth582iCvhYBmI03MrP2MiSrLU+UHdjbskWRcT1Ez2gU3Tk6N3of+m4lcsVPJAaI\nfPETiQFixRJqRJR58rrJa/r4dkc6cpV91KtLUUym9JFpbIu+3crsOacSYngmvaoPnheeopBe9N4+\nWWmtzO2yBiHSkbNNgI3T21Ips2DPfkDBi1Ac0f6o3agtrks9d31iSvTdDueKn0gMEPniJxIDxMyl\n+pHUVcGoTQu9nzQQArS02DP/ZBgV8+id8kDzDHiM8jLt7BOqiqECcXjGTZEhjYJ3bhQww0uIYYgo\ntWewpO6/1wd1LxVl5vvgZdZV7XrzrJ5r5VHJ10TPHSNqt2/gmlzxE4kBYuYrvqUoUvpUD2pl9VZ/\nVS8LlSKTTcUOWIim4Pmcq5Wo5SuvwlZxrvRW+wJgXkjm6e7Vyszu04899lhXPvPMMxfUFfWBV1YO\nEqlyx0cOMl7wSeXb7/UhSscVCQK9Z8WOe3X1EfSq5y0K05Zx9ROJRIh88ROJAWLFUmgZnfH05kow\nFgn0gHbTSaZ8XBdvC5SgUFFyT1cdUTaP6lns9VNPPXVBX7gOr18MGyfX5fXHzj18+HB3bM+ePV35\n9NNPBzCeQddDpGvmsdv2LwprxfPJc85zY+d41NjaVc9XS13enKt7qYSdXl1RSrfoGbetYKvQPFf8\nRGKAyBc/kRggZkr1jzvuuE4irPSpTL8jiWkf01olyfX0uApeeCmjiHy9J7U3eNoIZVIbSZi9+VDS\n75You5bebOfOnd0xpo5PPvkkAGDTpk3yerUV4+t5G2SZdwHtbchQWy4eD4/XzuH7oOwsuF/eFsLm\nQ2lUJuuwPnrPXRRsJNIscL3cR+tDHy9LIFf8RGKQyBc/kRggWhNqPADgVwBeBPBCrfWKUsp6AF8B\nsBXAAwCuq7U+uVg9L7300oJsoWzU4ZlsKhrjScTtuBePTlEyhidpVcdUdlm1rfDged9ZvUxh1dx4\nnl48x0YbvboYzz77LABg+/bt3bEDBw505YMHDy6o35Oeq3n2gpSYwZAX/y+SVCuqbjSd+8L99Z41\n9axwXdFz6dWrPB8VZWd4bamAJEpbsRj6rPhvrLXuqrVeMfr74wBurrVeBODm0d+JRGIVYCnCvXcA\nuGpU/gLmgnB+LLrIvmJKCNYnhVakh40EgZ6Th6rX9MwtfYlCH3mMgPXsUSZhBU8XfcoppwBoCx9l\nCU/OP//87tj3v//9rnzo0CEAfmRdhhLeMpQwso8PvQe7jueZ2Y4J6iITWEAzEC/kV2Q/MNm/xepV\nvv0ek7D6lBPQYmhd8SuA/1NKubOU8sHRsU21VuOBjwDQot5EInHUofWz+vpa68OllFcA+FYp5Rf8\nY621llLkcj36UHwQANatW7ekziYSieVB04tfa3149P+hUso3MBdP/2ApZXOt9UApZTOAQ8611wO4\nHgDOO++8Omla6IVTUuaQXhRWtW3whFlKIMPnMkW0er1tg/IEjExnmZKzfpjR6rnIbfEYVB89k0+V\nXOPOO++Uv9u2ge+D56mn4g8w1P175plnumOnnXbagnM9HbryTPPaNWEyz70X8svmwxMu8nFlO6HM\nvxne/VV2C54gMBJWe2hJmnlKKeU0KwN4C4CfAfgm5lJnAZlCK5FYVWhZ8TcB+Mboa3s8gL+ptd5U\nSvkhgK+WUj4A4EEA1x25biYSieVE+OKPUmXtFMcfB/Dmvg1OBplg+uZFvjUwrYx0ux6VszaYmilP\nscm+qXNVKCov6YO1x6nCWyikgtpO8HwpDYGnT+e6TGd/6623dsc2bNiw4HfW4/M889i9bYzqg9L0\nsO5c1RXlMGQoys318z2P+s1Q42VKruwpWkxr1Xi88GB23/sEtgHSci+RGCRWLK6+faFawg9NE4M/\nWnm5Tm+VV0KlyJqPwcIq5Q/foltXUHH3GZFDThRM8/3vf393bPfu3V35Zz/7GQDgqaee6o6xpmap\n4/GceGx+PaGkysLr9WUyHgQwfp+YkfVJS6au4bKt/kp4zP3ier1nmDGZfixTaCUSCRf54icSA8TM\nqf4kPY0oPdBP52/nsvOPF602wjT6dI5Qy7poBU8oNbkdmoT1h9vicUXRank+uA6jlps3b+6OMf2+\n7bbbAABPP/10c1veGPk5UPPL47E+rl27VtYV2VGo3z1BJAvkmPZHUM+osnfg3/kZVTEdWgR1dk6m\n0EokEiHyxU8kBogVC73l/a4QSYv5OqZPBo8GR/VHEnED2wR4UmElmfYQpRlTtgjRtsID+9s/+uij\nAIBPfepT3THWd9sYzG9/Eor2exqGaB6URD3S7bdAaWq8MGzWHj+zUXIVz+tT1c/18rYgatdL6ab+\ndvvZdFYikTimkC9+IjFAzDyhhpJ+KvQxpGHJtJ1jnmQtUAYg3EfPK9C2FSoJwyT6SF2jc43itwSr\niOpig5K9e/cCGKfUDJsHz+BJzZMncY/uL8OMn9hwKIqiy1DGPi0elXYvPU2N2tp4ATPUNZ6Hqd0T\ntc2aPFfV1YJc8ROJAWLmK74hCi7IK6etcN4XMEpbpfT8LWmRVH70SHiognG2QAmbvMy71gc2A/ZW\nGmXq6ZmC2tzxqsb6dourz0zDMyWNVjsFj3nZcRac8rPA89CaL95jF8p0luvn1Z9X3mgV7pPhWMWB\nUPH++dzW0F9d35rOSiQSxxTyxU8kBogV886LdNWsoza9MR+zzK2TUGa2EfX1aL+iTUz1LWusF98+\nsgNQdJbr82L8G+3zss9G3nncXzZRtfF88pOf7I59+9vf7spf/OIXF7TF90QJqFpg/fXCh9nvvKWz\nbQcwvvWIMhRbv1pSiin6zts69uqzOfFyA/TZeiibDy8WhdF+24K0znuu+InEAJEvfiIxQLSm0FoH\n4HMAfg/H838VAAARlklEQVRzMfb/E4Dd6JlCq9a6QCruRSplymJ6Y6Y7KqrpIv0f60MrrA3VFwAL\n0oEBvk440iZEYEmu0cmWOVD6ZR7PI4880pWNYu7Zs6c7ZmmzgPltzhNPPNEdY7rLthN9gnIo3boC\n18n0/vDhw13ZtoBeXWo+GH3uj3oePbPiPvPR51mxc2wOl1uq/xkAN9VaL8Fc/L17kCm0EolVi3DF\nL6WsBfBvAPxHAKi1/hbAb0spU6XQmkw06em9VVBKL+DgNGgRjNnXmwWJkQWVBxM6ef7aDFs9PDsA\nC3fFK3f0ped2H3rooa7MTjomIProRz/aHYuCnrIwTeV4b7FlUMlHVVgxlVjUq4v7yMzME75NA5Vu\ni9tiRma2ADyu6PnxciGoNF72e6sFX8tZ2wA8CuCvSil3lVI+N4qvnym0EolVipYX/3gAlwP4bK31\nMgDPYoLW17lPn5tCq5RyRynlDs+dM5FIzBYtwr19APbVWm8f/f01zL34vVNobdmypfs4KJ9jNhVV\ndKaPsMNDtG1gRxDrT18HCIXI4YcRpUVS13n2B0Y9H3jgge4YC1iVAIqFZVyXncsCTo9+twqZAD1O\n5bvPNN1r16Lzcj6AaLuxHOa9yqyYx2VC0D7hvLzMvIs5Ii1bXP1a6yMA9pZSLh4dejOAu5EptBKJ\nVYtWy73/AuBLpZQTAdwH4P2Y+2hkCq1EYhWiNVvujwBcIX7qlUKr1tpRT5NyevRN0Zk+1NeDotxM\nbaOECsrjqoXWqmionimxtctJJZQHWouX3C9/+UsA47r3Sy65pCuz3nnTpjn5LJvpcr1XXDH3CJhp\nL9cPANu3b+/K69evB+BTz2i7EtFzb1thW0eeO076oTIvR56akY/9ZH0G5U3Idg9e1GDVF6/dyXlK\n77xEIuEiX/xEYoCYqXfemjVrFkjK2cjByzqrfmco6adHFY0+Mb1nzQJLrCNJqYok6wW5UCHHeGvD\nWx6bEzYGMeo8eZ0Cz5MZ6PBWgbUnr3jFK7ryW97yFgDAfffd1x3jPtjvrBXgudm/f788HkEluVC/\ne2bHfNzo9WOPPdYdiwK1MHj7pHIURglCvG2BigrMiUn60H7lAdpHiwLkip9IDBIrFmxTORVMkxd+\nEpFQyIQr3BavhpG/PguNbNVh4REjCr3EUMFDvYCS6ivPKxmvyCZUYgcaFV4KAD796U8DAK666qru\nGJsr33jjjQCAa665pjv2xje+sSt/5zvf6cq2+jODYvCKbasz6955lY6cVpQQjMfLqz+nB5usf7Js\n8GLaK2FkFHrNy/HA9iO2+reYqFsdFp8g/fETiYSLfPETiQFiplS/lNIJT5TpLIOpTZ8Y/AocGdWo\nGAvL+gii1BbBE+hF8PTw1t8zzzxz0T56wtAHH3ywK5u/PVNfFthdeOGFXdko8bXXXtsdO//887uy\n+em/4Q1v6I5t3bq1KzPVtzF4VJ9hAjkvyq465p1rZd4m8Tybvwhv71p93SfP9QS1rfA8BU3ox1tI\nLyux9cfmcDm98xKJxDGGfPETiQFi5lF2J6OcMsXtQ7kZStrLkm22FTD6FEXD9cCUWUlyPSrYJw2Y\n9dcLS6bqZzr6+OOPd2Wbb9YZc5n1+FdeeSUA4CMf+Uh3jE16bVugJOPAeORb0354WyoeW2um35Zt\nlM0Dzw3Xb3Oj7DUmy9ZfzzxYRUGeJsQWML4dMck/30em/coWwbY2SfUTiYSLfPETiQGiTEuvp8HG\njRvru971LgDzVLwloIYy6fQos5VZqnvOOed0ZZNcqwi5i/VH/R5JnlUfmQoy3eSxGdXjY0zPzdCF\nJckc3YjbsC0ER9PdsWOH7KPRxEOH5mOqMNU3w5KLLrqoO8bS8d27d3dlmwemsNwvFVOPoQxhPOMY\nNed8Lm9nFPh63hbY3PEc8Hh4/s0wrI9Wx8uNZ/DiGbI2wJ5ze5ZuuOEG7N+/P7TfzRU/kRggZirc\ne+655/CLX/xi7BgLI/jLy8Is+4rzKs5fPSXI468xO4+oCLYqAy6gs9aqL74S4k320RiGV9erX/3q\nrrxr1y4A4/PBuvnzzjtvQbv79u3ryix8sxXoxz/+cXeMffO5XpWW7P777+/KtiqxE8+WLVsWXAPM\nOwfxfPAKppgGr3pR6i+eW3Ud31MegzIV57bYh15lB2aGw0zA4AlcbUX2hL9KqOjFquA6bOwmRPWe\n5Unkip9IDBD54icSA0RLQo2LMZcqy7AdwH8F8NfomUKL/fGp/q7sCdyMXjFVZHrHunWjq+xvr/y1\nuV3uE4dGMorHQjimUkajmR7yGPjcjRs3AhjfwnhbBGX+yXp+Gxsf436rPjAtZU8w7oPNMwsCuS9K\nB84edUyJ7Ry+Z57gi69T7drc8FaEx8OU2sKC8RiZGlt/PCGdug/8fPC9Zt26zTnfB+7X61//egDj\n26yf/OQnXZnHZnVcfPHF3bGzzjqrK/Oc33XXXQDGBbItaImyu7vWuqvWugvAvwLwawDfQKbQSiRW\nLfpS/TcD+GWt9UEA78Bc6iyM/v93y9mxRCJx5NBXqv9uAH87KvdOoVVK6aiWUVCmXEy/uWz0iCkO\nUz2mX6an98whjfZ5tFNJZT1aaXUxtfaCJ1gd3C73m6XF5pXHVJ7nw+isF7aM6zLayBoR7iMHqTBq\n+8pXvrI7xma4SmLO7XIbyvvSm3Nrl89l+m3PjHcfmF7bnHkZjm1ueAz8fDB9VwlVoqjQ3hgsgvHO\nnTu7Y3v37l3QLx4PB+3gCMb83Nxzzz0A5t8NtW1SaF7xRzH13w7gf0/+1ppCy9vDJxKJ2aLPiv9W\nAP+31moJ03un0NqwYUO1r6+y3OMvK3+lbSXhLyh/sflraV9W/l0J53j18TLYWnve6jDpcASMC7MU\n02B4vup33HHHgnZ59Te/eLbW448q6+atDm6LVy3uowmgPvzhD3fHbrrppq58ww03ABi3IuS61HiY\nlfSJlc/9MkEuj9HLNDuZPRYYfz7MapHrV/EagHlHI2/uuD92HdfFTjZm1cjt8tywMNLGxmyM7zWX\n7dkz4WBLdmKg3x7/PZin+UCm0EokVi2aXvxRWuyrAXydDv85gKtLKXsA/P7o70QisQrQmkLrWQAb\nJo49jp4ptEopCyiaSn8EaF22J6BioY9RPL6ehSHK191zrLEtAAt8mOYaPP2ycsjxwi0xHbXruN9K\niObRVd5uWHt8jCMF29YIAC644AIA4zYSl19+eVe+++67AQC33nrrgr5MjmFyLMD4PYsiyPLYbLvi\n3Qfl4MS2HXx/jXI/+uij8nqLSQDMzw2HH2MbB9ad2/zyHBw8eLArm0k1C055W8HPkNlpmNkzMP48\nb9u2rSvfe++9AObv85Gg+olE4hhBvviJxACx4gk1PG8lpaP29MCK5nK9KjEF/87SWRX5lmkl99Hq\nZfNgz2fczmEJMVN5FXrJ2zaYHp/7zfSdaa7VocxpgXlPP2Deg4/99dmz0STPXhwBprnKszGKhszb\nGZ5H5XHpmTvbPHC/eJ6t7zwfnhmu1cWej2y+q7QQXoIYGw/PJz+XrMGx+8rbM9YQKJ2/6fEz9FYi\nkXCRL34iMUDMnOobjBJ51IRpnQp44BmhGE3i7KPchrIe5G0F0ysrM41mWqhMevl6psS2HeG6PAMe\no/p8LsMkwA8//HB3jCkmj9365lFupo3vfOc7AYxTUJZov/Wtb11wjddHBS+TrMELzaVMdj2pvc0z\n03AVoZbvE99Ttd3k+8QmzA899FBXNqMa3jqp4Bpsds7PHc+p9Y2v53vKc2fPgs1Xayi9XPETiQFi\npiv+ySef3DkpmIOCFwIpyknu6YHtOK8Ir3rVq7ry7bffvqBdRpTTnhF9XZWgxxNKscmmCYB4heN+\n/ehHPwLgr7Y//elPu7IKNcZOLTzPthrxSsar/9lnnw1gXNCkHJEY3C4HvVQrXBR8kn/nueNzbZ54\nvji2vwnnmAF5+Q1spWeWyGNkgZzNE/eFV3Trg2czwrB6ldASGA92av21+9Aa7DNX/ERigMgXP5EY\nIGZK9V988cWOshjtU4I5O9dgNIqP8XUq1RTTQo73zhloFVR6Iq6L6Zv1hwWN3BcV8dT7nc0/mW4a\nmBrbtoBpNm9tVJgubxvFuO222wCMU2PegliEZBZwseCLqavVweNln3KVQkt5RnK93BbfB96OqPj2\nPM+W0Ze3O9wXDnFl993zBFRbUG6L59zug7fV4y2EPU+XXnppd4wjJ/P8Wx3mydeatTdX/ERigMgX\nP5EYIGaeUMNot1Fq9lbysoMaPWKKytsCPteCUDCVYwqqvOSY3jFVssQR3Ef26jIazGacnreamX16\n/WKY9Jzpu9Kde1sQPm4edTx3PEY+fueddwIA3vve9y4YIwDccsstAPxMwyx5PvfccwGMU182bWbd\nudFcvl6FsOL7zM8KawtM48FUn7dv9tx4IcFUFGTut0pPxtd5mh67lxxOi/vA3nk2Np47/p2fMWvP\nzMpTqp9IJFzki59IDBAzpfrPP/98Fy/Ocq4xNWKawh5RRgsVtQLGJaIWKMFLbGDUlqX7TKmZbqrI\nuMqAw0veweabFimY+8VjYOpq3nfcL5b6G63z5o5h7TLd9QySbJv03e9+tzvG/TWjK6aaXBfHiGNz\nYsMll1zSlVlCb2NjL0hlYMOx5ni+1P3n63krFmlaeLwGvk8Mdd/5nvBzZ323eIrA+NxxXdZHft45\n+Qafa+O1LUya7CYSCRel9QuxHDjxxBOrCWJsVfNCUSmT3BZzx0lhRwtYcKZCF3mxytXc8crLgjNj\nLVwXp1NSeQC8KL3WRkvMeoMXDVfFH+CVhld3G4MX3slL02WIssN6z6K6196zYH2L/NJ5Drw4AFYv\nz5Gnh1fh0tQ947qYhXksysBzy2zGhIXGSn7wgx/g8OHDiwc+QK74icQgkS9+IjFAzJTql1IeBfAs\ngMeic1cpzsSxObYc1+rB+bXWjdFJM33xAaCUcket9YqZNjojHKtjy3Ede0iqn0gMEPniJxIDxEq8\n+NevQJuzwrE6thzXMYaZ7/ETicTKI6l+IjFAzPTFL6VcU0rZXUq5t5Ty8Vm2vZwopZxbSrmllHJ3\nKeXnpZQPjY6vL6V8q5SyZ/T/GSvd12lQSllTSrmrlHLj6O9tpZTbR/ftK6UUHZLmKEcpZV0p5Wul\nlF+UUu4ppbz2WLlnfTGzF7+UsgbA/wTwVgA7ALynlLJj8auOWrwA4E9qrTsAvAbAH43G8nEAN9da\nLwJw8+jv1YgPAbiH/v4LAH9Za70QwJMAPrAivVo6PgPgplrrJQB2Ym6Mx8o964da60z+AXgtgH+k\nvz8B4BOzav8Ij+3vAVwNYDeAzaNjmwHsXum+TTGWLZh7Ad4E4EYABXNGLser+7ha/gFYC+B+jORa\ndHzV37Np/s2S6p8DYC/9vW90bFWjlLIVwGUAbgewqdZqSc0fAbDJuexoxqcBfBSAeYpsAPBUrdU8\nQ1brfdsG4FEAfzXaxnyulHIKjo171hsp3FsCSimnAvg7AH9caz3Mv9W5JWRVqUxKKW8DcKjWeudK\n9+UI4HgAlwP4bK31MsyZjo/R+tV4z6bFLF/8hwGcS39vGR1blSilnIC5l/5Ltdavjw4fLKVsHv2+\nGcAh7/qjFK8D8PZSygMAvow5uv8ZAOtKKeZPulrv2z4A+2qtt4/+/hrmPgSr/Z5NhVm++D8EcNFI\nQnwigHcD+OYM2182lDlH7RsA3FNr/RT99E0A7xuV34e5vf+qQa31E7XWLbXWrZi7P/9Ua/1DALcA\nuHZ02qobFwDUWh8BsLeUcvHo0JsB3I1Vfs+mxay98/4Ac3vINQA+X2v9s5k1vowopbwewHcA/BTz\ne+E/xdw+/6sAzgPwIIDraq1PyEqOcpRSrgLwkVrr20op2zHHANYDuAvAf6i1Lkw7fJSjlLILwOcA\nnAjgPgDvx9zid0zcsz5Iy71EYoBI4V4iMUDki59IDBD54icSA0S++InEAJEvfiIxQOSLn0gMEPni\nJxIDRL74icQA8f8Bc3g8WoSc9nsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6ae5a55c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "obs,r,done,_=env.step(1)\n",
    "print(r, done)\n",
    "plt.imshow(obs[0],cmap='gray',interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using simple convolutional neural network.\n",
    "\n",
    "![scheme](https://s18.postimg.org/gbmsq6gmx/dqn_scheme.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=device=cuda,floatX=float32\n"
     ]
    }
   ],
   "source": [
    "#setup and import theano/lasagne. Prefer GPU\n",
    "%env THEANO_FLAGS=device=cuda,floatX=float32\n",
    "\n",
    "import theano, lasagne\n",
    "from lasagne.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#observation\n",
    "observation_layer = InputLayer((None,)+observation_shape,)\n",
    "\n",
    "#4-tick window over images\n",
    "from agentnet.memory import WindowAugmentation, LSTMCell\n",
    "\n",
    "prev_wnd = InputLayer((None,4)+observation_shape)\n",
    "new_wnd = WindowAugmentation(observation_layer,prev_wnd)\n",
    "        \n",
    "#reshape to (frame, h,w). If you don't use grayscale, 4 should become 12.\n",
    "wnd_reshape = reshape(new_wnd, (-1,4*observation_shape[0])+observation_shape[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne.nonlinearities import elu,tanh,softmax\n",
    "#main neural network body.\n",
    "#note that we use batch normalization here which speeds up training but may\n",
    "#get unstable if you use small experience replay buffer\n",
    "conv0 = Conv2DLayer(wnd_reshape,32,filter_size=(8,8),stride=(4,4),name='conv0')\n",
    "\n",
    "conv1 = Conv2DLayer(batch_norm(conv0),64,filter_size=(4,4),stride=(2,2),name='conv1')\n",
    "\n",
    "dense = DenseLayer(batch_norm(conv1),512,name='dense',nonlinearity = lasagne.nonlinearities.tanh)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#baseline for all qvalues\n",
    "qvalues_layer = DenseLayer(dense,n_actions,nonlinearity=None,name='qval')\n",
    "        \n",
    "#sample actions proportionally to policy_layer\n",
    "from agentnet.resolver import EpsilonGreedyResolver\n",
    "action_layer = EpsilonGreedyResolver(qvalues_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.target_network import TargetNetwork\n",
    "targetnet = TargetNetwork(qvalues_layer)\n",
    "qvalues_old = targetnet.output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=(qvalues_layer,qvalues_old),\n",
    "              agent_states={new_wnd:prev_wnd},\n",
    "              action_layers=action_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[conv0.W,\n",
       " conv0_bn.beta,\n",
       " conv0_bn.gamma,\n",
       " conv1.W,\n",
       " conv1_bn.beta,\n",
       " conv1_bn.gamma,\n",
       " dense.W,\n",
       " dense.b,\n",
       " qval.W,\n",
       " qval.b]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(action_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 21:58:28,080] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 21:58:28,089] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 21:58:28,096] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 21:58:28,104] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 21:58:28,111] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 21:58:28,119] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 21:58:28,127] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 21:58:28,135] Making new env: ppaquette/DoomDefendCenter-v0\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "\n",
    "pool = EnvPool(agent,make_env, \n",
    "               n_games=N_AGENTS,\n",
    "               max_size=300) #experience replay pool holding last 1k sessions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3 3 3 3 3 0]\n",
      " [3 3 1 3 3 3 3]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "CPU times: user 192 ms, sys: 20 ms, total: 212 ms\n",
      "Wall time: 620 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_,action_log,reward_log,_,_,_  = pool.interact(7)\n",
    "\n",
    "\n",
    "print(action_log[:2])\n",
    "print(reward_log[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100,replace=True)\n",
    "\n",
    "_,_,_,_,(qvalues_seq,old_qvalues_seq) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning import qlearning\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "elwise_mse_loss = qlearning.get_elementwise_objective(qvalues_seq,\n",
    "                                                      replay.actions[0],\n",
    "                                                      replay.rewards,\n",
    "                                                      replay.is_alive,\n",
    "                                                      qvalues_target=old_qvalues_seq,\n",
    "                                                      gamma_or_gammas=0.99)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.adam(loss,weights)\n",
    "\n",
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 21:59:01,055] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 21:59:01,064] Clearing 12 monitor files from previous run (because force=True was provided)\n",
      "[2017-06-26 21:59:01,314] Starting new video recorder writing to /home/ubuntu/records/openaigym.video.0.15673.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 54 timesteps with reward=-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 21:59:02,933] Starting new video recorder writing to /home/ubuntu/records/openaigym.video.0.15673.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 72 timesteps with reward=0.0\n",
      "Episode finished after 53 timesteps with reward=-1.0\n",
      "Episode finished after 63 timesteps with reward=0.0\n",
      "Episode finished after 48 timesteps with reward=-1.0\n",
      "Episode finished after 53 timesteps with reward=-1.0\n",
      "Episode finished after 84 timesteps with reward=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 21:59:09,741] Starting new video recorder writing to /home/ubuntu/records/openaigym.video.0.15673.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 54 timesteps with reward=-1.0\n",
      "Episode finished after 55 timesteps with reward=-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 21:59:12,162] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 60 timesteps with reward=-1.0\n"
     ]
    }
   ],
   "source": [
    "action_layer.epsilon.set_value(0)\n",
    "untrained_reward = np.mean(pool.evaluate(save_path=\"./records\",record_video=True,n_games=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"./records/openaigym.video.0.15673.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show video\n",
    "from IPython.display import HTML\n",
    "import os\n",
    "\n",
    "video_names = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(\"./records/\"+video_names[-1])) #this may or may not be _last_ video. Try other indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "\n",
    "#full game rewards\n",
    "rewards = {0:[untrained_reward]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/2000 [00:10<34:40,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=10\tepsilon=0.954\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/2000 [00:20<34:10,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=20\tepsilon=0.910\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 30/2000 [00:30<33:49,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=30\tepsilon=0.868\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 40/2000 [00:40<33:33,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=40\tepsilon=0.828\treward/step=-0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 49/2000 [00:50<33:09,  1.02s/it][2017-06-26 22:00:03,333] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:00:03,338] Clearing 8 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=50\tepsilon=0.790\treward/step=-0.02500\n",
      "Episode finished after 74 timesteps with reward=1.0\n",
      "Episode finished after 54 timesteps with reward=1.0\n",
      "Episode finished after 65 timesteps with reward=0.0\n",
      "Episode finished after 76 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:00:08,148] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      "  2%|▎         | 50/2000 [00:55<1:20:27,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 72 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 60/2000 [01:06<34:52,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=60\tepsilon=0.754\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 70/2000 [01:16<33:04,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=70\tepsilon=0.719\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 80/2000 [01:26<32:46,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=80\tepsilon=0.687\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 90/2000 [01:36<32:37,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=90\tepsilon=0.656\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 99/2000 [01:45<32:11,  1.02s/it][2017-06-26 22:00:59,046] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:00:59,051] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=100\tepsilon=0.626\treward/step=0.02500\n",
      "Episode finished after 58 timesteps with reward=1.0\n",
      "Episode finished after 73 timesteps with reward=0.0\n",
      "Episode finished after 58 timesteps with reward=0.0\n",
      "Episode finished after 56 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:01:03,315] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      "  5%|▌         | 100/2000 [01:51<1:13:34,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 56 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 110/2000 [02:01<34:10,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=110\tepsilon=0.598\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 120/2000 [02:11<31:55,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=120\tepsilon=0.571\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 130/2000 [02:21<31:54,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=130\tepsilon=0.546\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 140/2000 [02:31<31:37,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=140\tepsilon=0.522\treward/step=-0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 149/2000 [02:40<31:20,  1.02s/it][2017-06-26 22:01:54,261] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:01:54,266] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=150\tepsilon=0.499\treward/step=0.02500\n",
      "Episode finished after 65 timesteps with reward=0.0\n",
      "Episode finished after 80 timesteps with reward=3.0\n",
      "Episode finished after 48 timesteps with reward=0.0\n",
      "Episode finished after 64 timesteps with reward=-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:01:59,042] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      "  8%|▊         | 150/2000 [02:46<1:16:08,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 84 timesteps with reward=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 160/2000 [02:56<32:30,  1.06s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=160\tepsilon=0.477\treward/step=-0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 170/2000 [03:07<31:23,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=170\tepsilon=0.456\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 180/2000 [03:17<31:24,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=180\tepsilon=0.436\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 190/2000 [03:27<31:52,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=190\tepsilon=0.417\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 199/2000 [03:36<30:41,  1.02s/it][2017-06-26 22:02:50,024] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:02:50,028] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=200\tepsilon=0.399\treward/step=0.00000\n",
      "Episode finished after 80 timesteps with reward=2.0\n",
      "Episode finished after 74 timesteps with reward=1.0\n",
      "Episode finished after 63 timesteps with reward=0.0\n",
      "Episode finished after 57 timesteps with reward=-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:02:55,044] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 10%|█         | 200/2000 [03:42<1:16:23,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 82 timesteps with reward=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 210/2000 [03:53<32:07,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=210\tepsilon=0.382\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 220/2000 [04:03<30:38,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=220\tepsilon=0.366\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 230/2000 [04:13<30:36,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=230\tepsilon=0.351\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 240/2000 [04:23<30:01,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=240\tepsilon=0.336\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 249/2000 [04:32<29:22,  1.01s/it][2017-06-26 22:03:45,902] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:03:45,907] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=250\tepsilon=0.322\treward/step=0.02500\n",
      "Episode finished after 82 timesteps with reward=1.0\n",
      "Episode finished after 79 timesteps with reward=2.0\n",
      "Episode finished after 96 timesteps with reward=4.0\n",
      "Episode finished after 98 timesteps with reward=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:03:52,178] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 12%|█▎        | 250/2000 [04:39<1:25:02,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 96 timesteps with reward=4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 260/2000 [04:50<31:21,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=260\tepsilon=0.309\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 270/2000 [05:00<29:30,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=270\tepsilon=0.296\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 280/2000 [05:10<30:09,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=280\tepsilon=0.284\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 290/2000 [05:20<29:17,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=290\tepsilon=0.273\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 299/2000 [05:29<28:46,  1.01s/it][2017-06-26 22:04:43,101] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:04:43,108] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=300\tepsilon=0.262\treward/step=0.03750\n",
      "Episode finished after 74 timesteps with reward=4.0\n",
      "Episode finished after 91 timesteps with reward=4.0\n",
      "Episode finished after 88 timesteps with reward=3.0\n",
      "Episode finished after 105 timesteps with reward=5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:04:49,206] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 15%|█▌        | 300/2000 [05:36<1:21:13,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 82 timesteps with reward=5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 310/2000 [05:47<30:31,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=310\tepsilon=0.252\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 320/2000 [05:57<29:11,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=320\tepsilon=0.242\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 330/2000 [06:07<28:42,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=330\tepsilon=0.232\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 340/2000 [06:17<28:17,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=340\tepsilon=0.224\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 349/2000 [06:26<27:58,  1.02s/it][2017-06-26 22:05:40,139] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:05:40,145] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=350\tepsilon=0.215\treward/step=0.06250\n",
      "Episode finished after 162 timesteps with reward=7.0\n",
      "Episode finished after 85 timesteps with reward=3.0\n",
      "Episode finished after 111 timesteps with reward=5.0\n",
      "Episode finished after 98 timesteps with reward=4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:05:47,281] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 18%|█▊        | 350/2000 [06:35<1:27:33,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 63 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 360/2000 [06:45<29:52,  1.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=360\tepsilon=0.207\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 370/2000 [06:55<27:53,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=370\tepsilon=0.199\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 380/2000 [07:05<27:52,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=380\tepsilon=0.192\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 390/2000 [07:15<27:35,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=390\tepsilon=0.185\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 399/2000 [07:24<27:03,  1.01s/it][2017-06-26 22:06:38,102] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:06:38,107] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=400\tepsilon=0.179\treward/step=0.00000\n",
      "Episode finished after 86 timesteps with reward=2.0\n",
      "Episode finished after 141 timesteps with reward=7.0\n",
      "Episode finished after 103 timesteps with reward=5.0\n",
      "Episode finished after 58 timesteps with reward=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:06:44,830] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 20%|██        | 400/2000 [07:32<1:21:22,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 97 timesteps with reward=4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 410/2000 [07:42<28:43,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=410\tepsilon=0.172\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 420/2000 [07:53<27:10,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=420\tepsilon=0.166\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 430/2000 [08:03<26:59,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=430\tepsilon=0.161\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 440/2000 [08:13<26:49,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=440\tepsilon=0.155\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 449/2000 [08:22<26:30,  1.03s/it][2017-06-26 22:07:35,904] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:07:35,910] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=450\tepsilon=0.150\treward/step=0.05000\n",
      "Episode finished after 78 timesteps with reward=2.0\n",
      "Episode finished after 66 timesteps with reward=2.0\n",
      "Episode finished after 87 timesteps with reward=2.0\n",
      "Episode finished after 86 timesteps with reward=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:07:41,194] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 22%|██▎       | 450/2000 [08:28<1:07:52,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 63 timesteps with reward=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 460/2000 [08:39<27:29,  1.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=460\tepsilon=0.145\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 470/2000 [08:49<26:24,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=470\tepsilon=0.141\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 480/2000 [08:59<25:54,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=480\tepsilon=0.136\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 490/2000 [09:09<25:50,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=490\tepsilon=0.132\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 499/2000 [09:18<25:27,  1.02s/it][2017-06-26 22:08:32,047] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:08:32,053] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=500\tepsilon=0.128\treward/step=0.03750\n",
      "Episode finished after 91 timesteps with reward=3.0\n",
      "Episode finished after 100 timesteps with reward=4.0\n",
      "Episode finished after 98 timesteps with reward=4.0\n",
      "Episode finished after 109 timesteps with reward=5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:08:38,727] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 25%|██▌       | 500/2000 [09:26<1:15:58,  3.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 83 timesteps with reward=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 510/2000 [09:36<27:02,  1.09s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=510\tepsilon=0.124\treward/step=0.06250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 520/2000 [09:46<25:28,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=520\tepsilon=0.121\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 530/2000 [09:56<24:57,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=530\tepsilon=0.117\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 540/2000 [10:07<24:59,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=540\tepsilon=0.114\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 549/2000 [10:16<24:39,  1.02s/it][2017-06-26 22:09:29,515] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:09:29,521] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=550\tepsilon=0.111\treward/step=0.08750\n",
      "Episode finished after 76 timesteps with reward=2.0\n",
      "Episode finished after 104 timesteps with reward=4.0\n",
      "Episode finished after 110 timesteps with reward=5.0\n",
      "Episode finished after 83 timesteps with reward=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:09:35,802] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 28%|██▊       | 550/2000 [10:23<1:10:41,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 82 timesteps with reward=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 560/2000 [10:33<26:00,  1.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=560\tepsilon=0.108\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 570/2000 [10:43<24:41,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=570\tepsilon=0.105\treward/step=0.05000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 580/2000 [10:54<24:27,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=580\tepsilon=0.102\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 590/2000 [11:04<24:05,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=590\tepsilon=0.100\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 599/2000 [11:13<23:48,  1.02s/it][2017-06-26 22:10:26,759] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:10:26,764] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=600\tepsilon=0.097\treward/step=-0.01250\n",
      "Episode finished after 56 timesteps with reward=2.0\n",
      "Episode finished after 53 timesteps with reward=1.0\n",
      "Episode finished after 73 timesteps with reward=0.0\n",
      "Episode finished after 52 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:10:30,957] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 30%|███       | 600/2000 [11:18<53:39,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 65 timesteps with reward=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 610/2000 [11:28<24:42,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=610\tepsilon=0.095\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 620/2000 [11:39<23:55,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=620\tepsilon=0.093\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 630/2000 [11:49<23:21,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=630\tepsilon=0.091\treward/step=-0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 640/2000 [11:59<23:19,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=640\tepsilon=0.089\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 649/2000 [12:08<22:53,  1.02s/it][2017-06-26 22:11:21,707] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:11:21,712] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=650\tepsilon=0.087\treward/step=0.03750\n",
      "Episode finished after 50 timesteps with reward=0.0\n",
      "Episode finished after 54 timesteps with reward=0.0\n",
      "Episode finished after 84 timesteps with reward=1.0\n",
      "Episode finished after 80 timesteps with reward=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:11:26,752] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 32%|███▎      | 650/2000 [12:14<57:27,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 94 timesteps with reward=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 660/2000 [12:24<24:04,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=660\tepsilon=0.085\treward/step=0.05000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 670/2000 [12:34<23:05,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=670\tepsilon=0.083\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 680/2000 [12:45<22:39,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=680\tepsilon=0.082\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 690/2000 [12:55<22:24,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=690\tepsilon=0.080\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 699/2000 [13:04<21:45,  1.00s/it][2017-06-26 22:12:17,550] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:12:17,556] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=700\tepsilon=0.079\treward/step=0.02500\n",
      "Episode finished after 80 timesteps with reward=2.0\n",
      "Episode finished after 54 timesteps with reward=0.0\n",
      "Episode finished after 60 timesteps with reward=0.0\n",
      "Episode finished after 44 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:12:21,726] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 35%|███▌      | 700/2000 [13:09<49:23,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 60 timesteps with reward=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 710/2000 [13:19<22:56,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=710\tepsilon=0.077\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 720/2000 [13:29<22:02,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=720\tepsilon=0.076\treward/step=0.05000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 730/2000 [13:40<21:47,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=730\tepsilon=0.075\treward/step=0.05000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 740/2000 [13:50<21:28,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=740\tepsilon=0.073\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 749/2000 [13:59<21:12,  1.02s/it][2017-06-26 22:13:12,624] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:13:12,629] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=750\tepsilon=0.072\treward/step=0.06250\n",
      "Episode finished after 95 timesteps with reward=3.0\n",
      "Episode finished after 98 timesteps with reward=5.0\n",
      "Episode finished after 101 timesteps with reward=5.0\n",
      "Episode finished after 102 timesteps with reward=6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:13:18,815] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 38%|███▊      | 750/2000 [14:06<1:00:18,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 52 timesteps with reward=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 760/2000 [14:16<22:44,  1.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=760\tepsilon=0.071\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 770/2000 [14:27<21:17,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=770\tepsilon=0.070\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 780/2000 [14:37<21:03,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=780\tepsilon=0.069\treward/step=0.07500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 790/2000 [14:47<20:55,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=790\tepsilon=0.068\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 799/2000 [14:56<20:13,  1.01s/it][2017-06-26 22:14:09,928] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:14:09,933] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=800\tepsilon=0.067\treward/step=0.00000\n",
      "Episode finished after 89 timesteps with reward=2.0\n",
      "Episode finished after 78 timesteps with reward=2.0\n",
      "Episode finished after 79 timesteps with reward=2.0\n",
      "Episode finished after 80 timesteps with reward=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:14:15,577] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 40%|████      | 800/2000 [15:03<54:27,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 78 timesteps with reward=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 810/2000 [15:13<21:31,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=810\tepsilon=0.067\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 820/2000 [15:23<20:14,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=820\tepsilon=0.066\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 830/2000 [15:34<20:06,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=830\tepsilon=0.065\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 840/2000 [15:44<19:49,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=840\tepsilon=0.064\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 849/2000 [15:53<19:34,  1.02s/it][2017-06-26 22:15:06,612] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:15:06,617] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=850\tepsilon=0.064\treward/step=-0.01250\n",
      "Episode finished after 120 timesteps with reward=5.0\n",
      "Episode finished after 99 timesteps with reward=2.0\n",
      "Episode finished after 102 timesteps with reward=4.0\n",
      "Episode finished after 83 timesteps with reward=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:15:13,339] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 42%|████▎     | 850/2000 [16:01<58:26,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 85 timesteps with reward=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 860/2000 [16:11<20:30,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=860\tepsilon=0.063\treward/step=-0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 870/2000 [16:21<19:22,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=870\tepsilon=0.062\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 880/2000 [16:31<19:12,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=880\tepsilon=0.062\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 890/2000 [16:41<19:02,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=890\tepsilon=0.061\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 899/2000 [16:50<18:32,  1.01s/it][2017-06-26 22:16:04,190] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:16:04,196] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=900\tepsilon=0.061\treward/step=0.00000\n",
      "Episode finished after 55 timesteps with reward=-1.0\n",
      "Episode finished after 53 timesteps with reward=-1.0\n",
      "Episode finished after 76 timesteps with reward=0.0\n",
      "Episode finished after 75 timesteps with reward=-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:16:08,508] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 45%|████▌     | 900/2000 [16:56<42:39,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 48 timesteps with reward=-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 910/2000 [17:06<19:14,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=910\tepsilon=0.060\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 920/2000 [17:16<18:30,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=920\tepsilon=0.060\treward/step=-0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 930/2000 [17:26<18:07,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=930\tepsilon=0.059\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 940/2000 [17:36<18:03,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=940\tepsilon=0.059\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 949/2000 [17:45<17:50,  1.02s/it][2017-06-26 22:16:59,036] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:16:59,042] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=950\tepsilon=0.058\treward/step=0.05000\n",
      "Episode finished after 119 timesteps with reward=5.0\n",
      "Episode finished after 181 timesteps with reward=7.0\n",
      "Episode finished after 102 timesteps with reward=5.0\n",
      "Episode finished after 86 timesteps with reward=4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:17:07,081] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 48%|████▊     | 950/2000 [17:54<1:00:22,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 94 timesteps with reward=5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 960/2000 [18:05<19:05,  1.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=960\tepsilon=0.058\treward/step=0.07500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 970/2000 [18:15<17:43,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=970\tepsilon=0.057\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 980/2000 [18:25<17:24,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=980\tepsilon=0.057\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 990/2000 [18:35<17:12,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=990\tepsilon=0.057\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 999/2000 [18:44<16:55,  1.01s/it][2017-06-26 22:17:57,958] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:17:57,963] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1000\tepsilon=0.056\treward/step=0.02500\n",
      "Episode finished after 41 timesteps with reward=-1.0\n",
      "Episode finished after 64 timesteps with reward=0.0\n",
      "Episode finished after 71 timesteps with reward=1.0\n",
      "Episode finished after 46 timesteps with reward=-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:18:01,825] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 50%|█████     | 1000/2000 [18:49<36:33,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 47 timesteps with reward=-1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1010/2000 [18:59<17:34,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1010\tepsilon=0.056\treward/step=0.06250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1020/2000 [19:09<16:42,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1020\tepsilon=0.056\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1030/2000 [19:20<16:39,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1030\tepsilon=0.056\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1040/2000 [19:30<16:36,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1040\tepsilon=0.055\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1049/2000 [19:39<16:12,  1.02s/it][2017-06-26 22:18:52,668] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:18:52,673] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1050\tepsilon=0.055\treward/step=0.03750\n",
      "Episode finished after 78 timesteps with reward=2.0\n",
      "Episode finished after 86 timesteps with reward=1.0\n",
      "Episode finished after 157 timesteps with reward=8.0\n",
      "Episode finished after 98 timesteps with reward=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:18:59,662] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 52%|█████▎    | 1050/2000 [19:47<49:38,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 90 timesteps with reward=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1060/2000 [19:57<16:59,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1060\tepsilon=0.055\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 1070/2000 [20:07<16:04,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1070\tepsilon=0.055\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1080/2000 [20:18<16:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1080\tepsilon=0.054\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1090/2000 [20:28<15:40,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1090\tepsilon=0.054\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 1099/2000 [20:37<15:17,  1.02s/it][2017-06-26 22:19:50,616] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:19:50,620] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1100\tepsilon=0.054\treward/step=0.05000\n",
      "Episode finished after 73 timesteps with reward=2.0\n",
      "Episode finished after 51 timesteps with reward=1.0\n",
      "Episode finished after 54 timesteps with reward=1.0\n",
      "Episode finished after 51 timesteps with reward=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:19:54,663] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 55%|█████▌    | 1100/2000 [20:42<33:47,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 56 timesteps with reward=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1110/2000 [20:52<15:46,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1110\tepsilon=0.054\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 1120/2000 [21:02<15:11,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1120\tepsilon=0.054\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 1130/2000 [21:13<15:04,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1130\tepsilon=0.053\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1140/2000 [21:23<14:48,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1140\tepsilon=0.053\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1149/2000 [21:32<14:32,  1.03s/it][2017-06-26 22:20:45,732] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:20:45,736] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1150\tepsilon=0.053\treward/step=0.00000\n",
      "Episode finished after 152 timesteps with reward=6.0\n",
      "Episode finished after 95 timesteps with reward=5.0\n",
      "Episode finished after 75 timesteps with reward=2.0\n",
      "Episode finished after 82 timesteps with reward=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:20:52,547] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 57%|█████▊    | 1150/2000 [21:40<43:41,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 90 timesteps with reward=4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1160/2000 [21:50<15:15,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1160\tepsilon=0.053\treward/step=0.07500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1170/2000 [22:00<14:19,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1170\tepsilon=0.053\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 1180/2000 [22:10<13:56,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1180\tepsilon=0.053\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 1190/2000 [22:20<13:54,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1190\tepsilon=0.052\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 1199/2000 [22:30<13:30,  1.01s/it][2017-06-26 22:21:43,361] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:21:43,367] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1200\tepsilon=0.052\treward/step=0.00000\n",
      "Episode finished after 47 timesteps with reward=0.0\n",
      "Episode finished after 63 timesteps with reward=0.0\n",
      "Episode finished after 59 timesteps with reward=0.0\n",
      "Episode finished after 40 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:21:47,162] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 60%|██████    | 1200/2000 [22:34<28:56,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 60 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 1210/2000 [22:45<13:58,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1210\tepsilon=0.052\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1220/2000 [22:55<13:18,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1220\tepsilon=0.052\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1230/2000 [23:05<13:08,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1230\tepsilon=0.052\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1240/2000 [23:15<13:04,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1240\tepsilon=0.052\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 1249/2000 [23:24<12:43,  1.02s/it][2017-06-26 22:22:37,868] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:22:37,873] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1250\tepsilon=0.052\treward/step=0.06250\n",
      "Episode finished after 108 timesteps with reward=6.0\n",
      "Episode finished after 135 timesteps with reward=8.0\n",
      "Episode finished after 95 timesteps with reward=4.0\n",
      "Episode finished after 148 timesteps with reward=8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:22:46,146] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 62%|██████▎   | 1250/2000 [23:33<43:58,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 115 timesteps with reward=7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 1260/2000 [23:44<13:39,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1260\tepsilon=0.052\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 1270/2000 [23:54<12:24,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1270\tepsilon=0.052\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1280/2000 [24:04<12:26,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1280\tepsilon=0.052\treward/step=0.06250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 1290/2000 [24:14<12:14,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1290\tepsilon=0.052\treward/step=0.06250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 1299/2000 [24:23<11:49,  1.01s/it][2017-06-26 22:23:37,086] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:23:37,091] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1300\tepsilon=0.051\treward/step=0.02500\n",
      "Episode finished after 58 timesteps with reward=0.0\n",
      "Episode finished after 78 timesteps with reward=1.0\n",
      "Episode finished after 62 timesteps with reward=-1.0\n",
      "Episode finished after 81 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:23:41,862] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 65%|██████▌   | 1300/2000 [24:29<28:45,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 64 timesteps with reward=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1310/2000 [24:39<12:14,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1310\tepsilon=0.051\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1320/2000 [24:49<11:44,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1320\tepsilon=0.051\treward/step=0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 1330/2000 [25:00<11:29,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1330\tepsilon=0.051\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1340/2000 [25:10<11:27,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1340\tepsilon=0.051\treward/step=0.07500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 1349/2000 [25:19<11:07,  1.03s/it][2017-06-26 22:24:32,830] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:24:32,836] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1350\tepsilon=0.051\treward/step=0.02500\n",
      "Episode finished after 82 timesteps with reward=4.0\n",
      "Episode finished after 127 timesteps with reward=7.0\n",
      "Episode finished after 99 timesteps with reward=4.0\n",
      "Episode finished after 99 timesteps with reward=7.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:24:39,471] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 68%|██████▊   | 1350/2000 [25:27<32:51,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 74 timesteps with reward=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1360/2000 [25:37<11:35,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1360\tepsilon=0.051\treward/step=0.03750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 1370/2000 [25:47<10:41,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1370\tepsilon=0.051\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 1380/2000 [25:57<10:38,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1380\tepsilon=0.051\treward/step=-0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1390/2000 [26:07<10:29,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1390\tepsilon=0.051\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 1399/2000 [26:16<10:09,  1.01s/it][2017-06-26 22:25:30,174] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:25:30,180] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1400\tepsilon=0.051\treward/step=0.05000\n",
      "Episode finished after 91 timesteps with reward=2.0\n",
      "Episode finished after 91 timesteps with reward=1.0\n",
      "Episode finished after 80 timesteps with reward=2.0\n",
      "Episode finished after 204 timesteps with reward=10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:25:38,015] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 70%|███████   | 1400/2000 [26:25<33:50,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 106 timesteps with reward=5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 1410/2000 [26:35<10:45,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1410\tepsilon=0.051\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1420/2000 [26:46<09:53,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1420\tepsilon=0.051\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1430/2000 [26:56<09:54,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1430\tepsilon=0.051\treward/step=0.01250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1440/2000 [27:06<09:37,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1440\tepsilon=0.051\treward/step=0.06250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 1449/2000 [27:15<09:22,  1.02s/it][2017-06-26 22:26:28,836] Making new env: ppaquette/DoomDefendCenter-v0\n",
      "[2017-06-26 22:26:28,841] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1450\tepsilon=0.051\treward/step=0.06250\n",
      "Episode finished after 65 timesteps with reward=3.0\n",
      "Episode finished after 99 timesteps with reward=3.0\n",
      "Episode finished after 49 timesteps with reward=1.0\n",
      "Episode finished after 90 timesteps with reward=3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-06-26 22:26:33,955] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/ubuntu/records')\n",
      " 72%|███████▎  | 1450/2000 [27:21<23:35,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 63 timesteps with reward=2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1460/2000 [27:31<09:35,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1460\tepsilon=0.051\treward/step=0.00000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 1470/2000 [27:42<09:15,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1470\tepsilon=0.051\treward/step=-0.02500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1478/2000 [27:50<08:52,  1.02s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a56b9f0f380a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/AgentNet/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, n_steps, append, max_size, add_last_observation, preprocess)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Get interaction sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         observation_tensor, action_tensor, reward_tensor, _, is_alive_tensor, _ = self.interact(n_steps=n_steps,\n\u001b[0;32m--> 194\u001b[0;31m                                                                                                 add_last_observation=add_last_observation)\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mobservation_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_alive_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreceding_memory_states\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/AgentNet/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36minteract\u001b[0;34m(self, n_steps, verbose, add_last_observation)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_memory_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mnew_observations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_alive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;31m# Append data tuple for this tick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/AgentNet/agentnet/experiments/openai_gym/pool.py\u001b[0m in \u001b[0;36menv_step\u001b[0;34m(i, action)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjust_ended\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mnew_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_reward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0;31m# Game ends now, will finalize on next tick.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/gym/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/gym/gym/core.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/gym/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/gym/gym/wrappers/frame_skipping.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstepcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mcurrent_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/gym/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/env/lib/python3.5/site-packages/ppaquette_gym_doom/wrappers/action_space.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscreteToMultiDiscrete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mToDiscreteWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/gym/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/gym/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0mauxiliary\u001b[0m \u001b[0mdiagnostic\u001b[0m \u001b[0minformation\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhelpful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdebugging\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msometimes\u001b[0m \u001b[0mlearning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/env/lib/python3.5/site-packages/ppaquette_gym_doom/doom_env.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mlist_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_game_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "for i in trange(2000):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    pool.update(SEQ_LENGTH, append=True)\n",
    "    \n",
    "    loss = train_step()\n",
    "    \n",
    "    targetnet.load_weights(0.01)\n",
    "    \n",
    "    ##update resolver's epsilon (chance of random action instead of optimal one)\n",
    "    current_epsilon = 0.05 + 0.95*np.exp(-epoch_counter/200.)\n",
    "    action_layer.epsilon.set_value(np.float32(current_epsilon))\n",
    "    \n",
    "    if epoch_counter%10==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = pool.experience_replay.rewards.get_value().mean()\n",
    "        print(\"iter=%i\\tepsilon=%.3f\\treward/step=%.5f\"%(epoch_counter,\n",
    "                                                         current_epsilon,\n",
    "                                                         pool_mean_reward))\n",
    "        \n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%50 ==0:\n",
    "        rewards[epoch_counter] = pool.evaluate(5, record_video=False)\n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results\n",
    " * Here we plot learning curves and sample testimonials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time,rw = zip(*sorted(list(rewards.items()),key=lambda p:p[0]))\n",
    "plt.plot(time,list(map(np.mean,rw)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "tmp = GAME_NAME.split('/')[1]\n",
    "os.mkdir(tmp)\n",
    "with open('{}/{}'.format(tmp, tmp), 'w') as outp:\n",
    "    for idx in range(len(time)):\n",
    "        print(time[idx], rw[idx], file=outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_layer.epsilon.set_value(0.001)\n",
    "rw = pool.evaluate(n_games=100,save_path=\"./records\",record_video=True)\n",
    "print(\"mean session score=%f\"%np.mean(rw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.scoreboard.api_key = 'sk_X6PO6hv9Rq24jaL21xROSA'\n",
    "#gym.upload('/home/ubuntu/records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from agentnet.utils.persistence import save,load\n",
    "#save for display\n",
    "save(action_layer,\"{}/{}.pcl\".format(tmp, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import os\n",
    "from random import choice\n",
    "#select the one you want\n",
    "videos = list(filter(lambda s:s.endswith(\".mp4\"),os.listdir(\"./records/\")))\n",
    "video_path=\"./records/\"+choice(videos)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get serious\n",
    "\n",
    "* Switch to DoomDefendCenter, DoomHealthGathering, DoomDeathmatch or similar\n",
    "* Deploy a better RL algorithm\n",
    "* Deploy a better network. Doom will likely need some recurrent nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
